{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549b8fc7",
   "metadata": {},
   "source": [
    "## Pipeline Script \n",
    "This script "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed04e7",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b02078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f51435",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c02784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [BBLID, Session, SCANID_CEST, sex, race, ethnic, dateDiff, THA, CAU, THA_btwn, CAU_btwn, avgCEST_Thal, ctCEST_Thal, avgCEST_Caudate, ctCEST_Caudate, tap_tot, hstatus, age]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "fcpath = \"/Users/pecsok/Desktop/ImageData/PMACS_remote/data/fmri/postprocessed/3T/xcp_d\"\n",
    "outpath = \"~/Desktop/ImageData/PMACS_remote/analysis/postprocessing/\"\n",
    "clinpath = \"~/Desktop/ImageData/PMACS_remote/data/clinical\"\n",
    "cestpath = \"~/Desktop/ImageData/PMACS_remote/data/cest\"\n",
    "\n",
    "# Choose what to analyse\n",
    "#networks = [\"Cont\", \"Default\", \"DorsAttn\", \"Vis\", \"SalVentAttn\", \"SomMot\", \"Limbic\"] \n",
    "networks = [\"THA\",\"CAU\"] \n",
    "#btwn_ntwks = [\"Cont_btwn\", \"Default_btwn\", \"DorsAttn_btwn\", \"Vis_btwn\", \"SalVentAttn_btwn\", \"SomMot_btwn\", \"Limbic_btwn\"] \n",
    "btwn_ntwks = [\"THA_btwn\",\"CAU_btwn\"] \n",
    "#all_ntwks = [\"Cont_all\", \"Default_all\", \"DorsAttn_all\", \"Vis_all\", \"SalVentAttn_all\", \"SomMot_all\", \"Limbic_all\"] \n",
    "all_ntwks = [\"THA_all\",\"CAU_all\"] \n",
    "networkscest = [\"Right Thalamus \",\"Right Caudate \"] \n",
    "\n",
    "\n",
    "CESTnetworks = [\"avgCEST_Thal\", \"ctCEST_Thal\", \"avgCEST_Caudate\", \"ctCEST_Caudate\"]\n",
    "\n",
    "CNB_scores = [\"tap_tot\"]\n",
    "CNB_valids = [\"tap_valid\"] \n",
    "diag_scores = [\"hstatus\",\"age\"]\n",
    "demo_scores = [\"sex\", \"race\",\"ethnic\",\"dateDiff\"]\n",
    "diag_details = [\"axis1_desc1\", \"axis1_desc2\", \"axis1_desc3\",\"axis1_desc4\",\"axis1_desc5\", \"axis1_desc6\"]\n",
    "\n",
    "\n",
    "# Make dataframe based on metrics of interest\n",
    "grp_df = pd.DataFrame(columns = [\"BBLID\"] + [\"Session\"] + [\"SCANID_CEST\"] + demo_scores + networks + btwn_ntwks + CESTnetworks + CNB_scores + diag_scores)\n",
    "diag_df = pd.DataFrame(columns = [\"BBLID\"] + [\"Session\"] + [\"SCANID_CEST\"] + diag_scores + diag_details)\n",
    "print(grp_df)\n",
    "\n",
    "# Initialize empty lists and vars\n",
    "bblids = []\n",
    "sesids = []\n",
    "gluseses = []\n",
    "\n",
    "# Import group dataframes and set indices\n",
    "subjlist = pd.read_csv(\"~/Desktop/ImageData/PMACS_remote/data/subject_list_031124.csv\", sep=',') \n",
    "subjlist = subjlist.dropna(subset=['BBLID'])\n",
    "subjlist['BBLID'] = subjlist['BBLID'].astype(int)\n",
    "subjlist['SCANID_CEST'] = subjlist['SCANID_CEST'].astype(int)\n",
    "cnbmat = pd.read_csv(clinpath + \"/maggie_datarequest_fullcnb-2.csv\", sep=',') \n",
    "diagmat = pd.read_csv(clinpath + \"/maggie_datarequest_diagnosis-2.csv\", sep=',')\n",
    "demomat = pd.read_csv(clinpath + \"/maggie_datarequest_demographics-2.csv\", sep=',')\n",
    "cestmat = pd.read_csv(cestpath + \"/compiled_outputs/compiled_cortical_UNI.csv\", sep=',')\n",
    "# cestmat = pd.read_csv(clinpath + \"/demographics.csv\", sep='\\t') add grp CEST map here\n",
    "cnbmat.set_index('bblid', inplace = True)\n",
    "diagmat.set_index('bblid', inplace = True)\n",
    "demomat.set_index('bblid', inplace = True)\n",
    "cestmat.set_index('Subject', inplace = True)\n",
    "\n",
    "# Set up renaming dictionary for CEST df\n",
    "schaefer_indices = pd.read_csv('~/Desktop/ImageData/PMACS_remote/github/glucest-rsfmri/Schaefer2018_100Parcels_17Networks_order_FSLMNI152_2mm.Centroid_RAS.csv', sep=',') # Load the CSV with the mapping of numbers to labels\n",
    "schaefer_dict = dict(zip(schaefer_indices['ROI Label'], schaefer_indices['ROI Name']))\n",
    "\n",
    "#print(subjlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c428aa5",
   "metadata": {},
   "source": [
    "### Choose which modules to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670d0539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runfcon = True\n",
    "runCNB = True\n",
    "rundiag = True\n",
    "rundemo = True\n",
    "runcest = True\n",
    "run_grpanalysis = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2359da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stage 1: Create Group Data Frame\n",
    "### Import data, loop through subjects, and establish file paths\n",
    "\n",
    "\n",
    "FIX THIS ERROR:\n",
    "/var/folders/ls/hy_z7hgd4_13km3h7j84vqh40000gp/T/ipykernel_77945/3898733492.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'PSY' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
    "  grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == diag_score] = diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "817bd7ed-5fee-491a-a27f-8c276dcd2769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    BBLID Session SCANID_CEST  sex  race  ethnic  dateDiff  THA  CAU  \\\n",
      "0  117847   12564       12740  1.0   1.0     2.0      18.0  NaN  NaN   \n",
      "1   20645   11274       11260  1.0   2.0     2.0       0.0  NaN  NaN   \n",
      "\n",
      "   THA_btwn  CAU_btwn  avgCEST_Thal  ctCEST_Thal  avgCEST_Caudate  \\\n",
      "0       NaN       NaN           NaN          NaN              NaN   \n",
      "1       NaN       NaN           NaN          NaN              NaN   \n",
      "\n",
      "   ctCEST_Caudate   tap_tot hstatus   age  THA_all  CAU_all  \n",
      "0             NaN  123.6667       O  21.9      NaN      NaN  \n",
      "1             NaN       NaN     NaN  19.8      NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "print(grp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba3234c-4125-4621-813b-b692b1e5dd61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 117847\n",
      "Running THA fcon\n",
      "Running CAU fcon\n",
      "117847_12740\n",
      "THA\n",
      "CAU\n",
      "Processing subject 20645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:65: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[len(grp_df)-1, network] = np.nanmean(network_fc.values)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:71: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, btwn_ntwk] = np.nanmean(btwn_fc)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:77: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, all_ntwk] = np.nanmean(all_fc)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:65: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[len(grp_df)-1, network] = np.nanmean(network_fc.values)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:71: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, btwn_ntwk] = np.nanmean(btwn_fc)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:77: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, all_ntwk] = np.nanmean(all_fc)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'O' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == diag_score] = diagnosis\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:117: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'O' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_score] = diagnosis\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:131: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Depressive Disorder NOS' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_detail] = comorbidity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running THA fcon\n",
      "Running CAU fcon\n",
      "20645_11260\n",
      "THA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:65: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[len(grp_df)-1, network] = np.nanmean(network_fc.values)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:71: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, btwn_ntwk] = np.nanmean(btwn_fc)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:77: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, all_ntwk] = np.nanmean(all_fc)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:65: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[len(grp_df)-1, network] = np.nanmean(network_fc.values)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:71: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, btwn_ntwk] = np.nanmean(btwn_fc)\n",
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_55686/2496764911.py:77: RuntimeWarning: Mean of empty slice\n",
      "  grp_df.loc[grp_df['BBLID'] == bblid, all_ntwk] = np.nanmean(all_fc)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Right Thalamus  NZMean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Right Thalamus  NZMean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 169\u001b[0m\n\u001b[1;32m    166\u001b[0m ct_cestmat \u001b[38;5;241m=\u001b[39m networkcest \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m NZcount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(cestid) \u001b[38;5;129;01min\u001b[39;00m cestmat\u001b[38;5;241m.\u001b[39mindex:    \n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m#print(\"yes\")\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m     cest_avgs \u001b[38;5;241m=\u001b[39m \u001b[43mcestmat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_cestmat\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    170\u001b[0m     cest_avg \u001b[38;5;241m=\u001b[39m cest_avgs[\u001b[38;5;28mstr\u001b[39m(cestid)]\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m#print(cest_avg)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Right Thalamus  NZMean'"
     ]
    }
   ],
   "source": [
    "# Generates list of all file names\n",
    "folder_names = [folder for folder in glob.glob(os.path.join(fcpath, \"*\")) if os.path.isdir(folder)]\n",
    "#subje\n",
    "\n",
    "# Loop through subjects\n",
    "for subj_path in folder_names: # loop through all rows of the spreadsheet\n",
    "    if \"sub\" in subj_path:\n",
    "        # Extract bblid id:\n",
    "        bblid = subj_path.split('-')[1]\n",
    "        print(\"Processing subject \" + bblid)\n",
    "        # Extract session id: \n",
    "        items = os.listdir(subj_path)\n",
    "        ses_folder = [item for item in items if item.startswith(\"ses\")]\n",
    "        ses = ses_folder[0].split('-')[1]\n",
    "        ses_path = os.path.join(fcpath, subj_path, ses_folder[0]) # full path to session\n",
    "        if bblid in subjlist['BBLID'].astype(str).values:\n",
    "            gluses = subjlist.loc[subjlist['BBLID'].astype(str) == bblid, 'SCANID_CEST'].values[0].astype(str) #.\n",
    "         # Add to running list of IDs grp analysis later:\n",
    "        bblids.append(bblid)\n",
    "        sesids.append(ses)\n",
    "        gluseses.append(gluses)\n",
    "        # Start new row in grp_df for this subject:\n",
    "        ids = [bblid, ses, gluses]  # Values for the first two columns\n",
    "        grp_df.loc[len(grp_df)] = ids + [float('nan')] * (len(grp_df.columns) - len(ids))\n",
    "        diag_df.loc[len(diag_df)] = ids + [float('nan')] * (len(diag_df.columns) - len(ids))   \n",
    "\n",
    "        # Run a subset of subjs or exclude specific subjs.\n",
    "        if bblid != \"20902\" and bblid != \"93242\"  and bblid != \"20754\" and bblid != \"127065\":\n",
    "            ##################################################################################################\n",
    "            ## FC\n",
    "            ##################################################################################################\n",
    "            if runfcon:\n",
    "                os.path.join(fcpath, \"sub-\" + bblid, \"ses-\" + ses)\n",
    "                ses_path = os.path.join(fcpath, subj_path, ses_folder[0]) # full path to session\n",
    "                fcmat_glob = f\"{ses_path}/func/*Schaefer117_measure-pearsoncorrelation_conmat.tsv\"\n",
    "                if os.path.isfile(glob.glob(fcmat_glob)[0]):\n",
    "                    fcmat = pd.read_csv(glob.glob(fcmat_glob)[0], sep='\\t') # read in fcmat\n",
    "                    fcmat.set_index('Node', inplace = True)\n",
    "                    print(fcmat)\n",
    "                    # Loop through the networks\n",
    "                    for i in range(len(networks)):\n",
    "                        network = networks[i]\n",
    "                        btwn_ntwk = btwn_ntwks[i]\n",
    "                        all_ntwk = all_ntwks[i]\n",
    "                        print(\"Running \" + network + \" fcon\")\n",
    "                        \n",
    "                        # Extract within-network FC\n",
    "                        mask = np.triu(np.ones_like(fcmat, dtype=bool))\n",
    "                        fcmat = fcmat.mask(mask)\n",
    "                        np.fill_diagonal(fcmat.values, 1)\n",
    "                        #print(fcmat)\n",
    "                        filtered_rows = fcmat.index.str.contains(network) & fcmat.index.str.contains(\"rh\")\n",
    "                        filtered_columns = fcmat.columns.str.contains(network) & fcmat.columns.str.contains(\"rh\")\n",
    "                        network_fc = fcmat.loc[filtered_rows, filtered_columns]\n",
    "                        # Calculate avg network fc and add value to proper column in grp_df\n",
    "                        grp_df.loc[len(grp_df)-1, network] = np.nanmean(network_fc.values)\n",
    "\n",
    "                        # Calculate between-network FC\n",
    "                        fcmat_all = fcmat.combine_first(fcmat.T)\n",
    "                        btwn_fc = fcmat.loc[filtered_rows, fcmat.columns[~filtered_columns]]\n",
    "                        # Calculate avg network fc and add value to proper column in grp_df\n",
    "                        grp_df.loc[grp_df['BBLID'] == bblid, btwn_ntwk] = np.nanmean(btwn_fc)\n",
    "\n",
    "                        # Calculate all FC\n",
    "                        np.fill_diagonal(fcmat.values, np.nan)\n",
    "                        all_fc = fcmat.loc[filtered_rows, :]\n",
    "                        # Calculate avg network fc and add value to proper column in grp_df\n",
    "                        grp_df.loc[grp_df['BBLID'] == bblid, all_ntwk] = np.nanmean(all_fc)\n",
    "            \n",
    "                        # Select rows and columns corresponding to the network\n",
    "                    #    np.fill_diagonal(fcmat.values, np.nan)\n",
    "                    #    fcmat['avg_fc'] = fcmat.mean(axis=1, skipna=True)\n",
    "                    #    fc_all = fcmat['avg_fc'].tail(50).values\n",
    "                       # last50 = pd.DataFrame(fc_last50).T\n",
    "                       # last50 = last50.rename(columns={i: str(i+1) for i in range(50)})\n",
    "                       # fc_parcelmat.iloc[fc_parcelmat['BBLID'] == bblid, 8:] = fc_last50 #fc_parcelmat.index == bblid\n",
    "\n",
    "            \n",
    "            ##################################################################################################\n",
    "            ## CNB\n",
    "            ##################################################################################################\n",
    "            if runCNB:\n",
    "                # Loop through the CNB scores\n",
    "                for i in range(len(CNB_scores)):\n",
    "                    CNB_score = CNB_scores[i]\n",
    "                    CNB_valid = CNB_valids[i]\n",
    "                    # Select score of interest & validity of that score\n",
    "                    scores = cnbmat[CNB_score]\n",
    "                    if int(bblid) in scores.index:\n",
    "                        score = scores[int(bblid)]\n",
    "                        valids = cnbmat[CNB_valid]\n",
    "                        valid = str(valids[int(bblid)])\n",
    "                        # If score was valid, add to grp_df\n",
    "                        if 'V' in valid: \n",
    "                            grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == CNB_score] = score \n",
    "            ##################################################################################################\n",
    "            ## Diagnosis\n",
    "            ##################################################################################################\n",
    "            if rundiag:\n",
    "                # Add hstatus\n",
    "                for i in range(len(diag_scores)):\n",
    "                    diag_score = diag_scores[i]\n",
    "                    # Select score of interest and add to grp_df\n",
    "                    diagnoses = diagmat[diag_score]\n",
    "                    if int(bblid) in diagnoses.index:\n",
    "                        diagnosis = diagnoses[int(bblid)]\n",
    "                        grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == diag_score] = diagnosis \n",
    "                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_score] = diagnosis \n",
    "                    else:\n",
    "                        diagnosis = \"Unknown\"\n",
    "                        grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == diag_score] = diagnosis \n",
    "                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_score] = diagnosis\n",
    "     \n",
    "                # Loop through diag scores\n",
    "                for i in range(len(diag_details)):\n",
    "                    diag_detail = diag_details[i]\n",
    "                    # Select score of interest and add to grp_df\n",
    "                    comorbidities = diagmat[diag_detail]\n",
    "                    if int(bblid) in comorbidities.index:\n",
    "                        comorbidity = comorbidities[int(bblid)]\n",
    "                       # print(comorbidity)\n",
    "                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_detail] = comorbidity \n",
    "                    else:\n",
    "                        comorbidity = \"Unknown\"\n",
    "                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_detail] = comorbidity\n",
    "            ##################################################################################################\n",
    "            ## Demographics\n",
    "            ##################################################################################################\n",
    "            if rundemo:\n",
    "                # Loop through the CNB scores\n",
    "                for i in range(len(demo_scores)):\n",
    "                    demo_score = demo_scores[i]\n",
    "                    # Select metric of interest\n",
    "                    scores = demomat[demo_score]\n",
    "                    if int(bblid) in scores.index:\n",
    "                        score = scores[int(bblid)]\n",
    "                        # Add to grp_df\n",
    "                        grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == demo_score] = score \n",
    "            ##################################################################################################\n",
    "            ## CEST\n",
    "            ##################################################################################################\n",
    "            if runcest and bblid != \"88760\": \n",
    "                #print(\"Processing \" + bblid + \"'s CEST data'\")\n",
    "                # Extract Glu Session ID\n",
    "                if bblid in subjlist['BBLID'].astype(str).values:\n",
    "                    gluses = subjlist.loc[subjlist['BBLID'].astype(str) == bblid, 'SCANID_CEST'].values[0].astype(str) #.\n",
    "                    cestid = bblid + \"_\" + gluses\n",
    "                    print(cestid)\n",
    "                    # Import data\n",
    "                    for i in range(len(networks)):\n",
    "                        network = networks[i]\n",
    "                        print(network)\n",
    "                        networkcest = networkscest[i]\n",
    "                        col_name = \"avgCEST_\" + network # for grp_df\n",
    "                        ct_name = \"ctCEST_\" + network # for grp_df\n",
    "                        col_cestmat = networkcest + \" NZMean\" # for CEST output \n",
    "                        ct_cestmat = networkcest + \" NZcount\"\n",
    "                        if str(cestid) in cestmat.index:    \n",
    "                            #print(\"yes\")\n",
    "                            cest_avgs = cestmat[col_cestmat]\n",
    "                            cest_avg = cest_avgs[str(cestid)]\n",
    "                            #print(cest_avg)\n",
    "                            cest_cts = cestmat[ct_cestmat]\n",
    "                            cest_ct = cest_cts[str(cestid)]\n",
    "                            grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == col_name] = cest_avg \n",
    "                            grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == ct_name] = cest_ct                            \n",
    "\n",
    "print(grp_df)\n",
    "# sum_of_mean_columns now contains the sum of values in columns with \"Mean\" in the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72d3c3f1-7fd2-495a-987e-e9c334629abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BBLID  Session SCANID_CEST  sex  race  ethnic  dateDiff      Cont  \\\n",
      "0   117847    12564       12740  1.0   1.0     2.0      18.0  0.083760   \n",
      "1    20645    11274       11260  1.0   2.0     2.0       0.0  0.266631   \n",
      "2   128865    12165       12325  1.0   1.0     2.0      49.0  0.080022   \n",
      "3   120217    10702       10722  2.0   1.0     2.0       8.0  0.170671   \n",
      "4    21118    12258       12784  2.0   1.0     2.0       0.0  0.155164   \n",
      "..     ...      ...         ...  ...   ...     ...       ...       ...   \n",
      "87  127935  motive2       12101  1.0   2.0     2.0      35.0  0.127090   \n",
      "88   94703    11928       12082  2.0   2.0     2.0      13.0  0.124214   \n",
      "89   91335     9346       12082  1.0   2.0     2.0     113.0  0.138340   \n",
      "90   89095     9972       11100  2.0   1.0     2.0       0.0  0.169108   \n",
      "91   20082  motive2       11821  2.0   1.0     2.0      18.0  0.033836   \n",
      "\n",
      "     Default  DorsAttn  ...  ctCEST_Vis  avgCEST_Limbic  ctCEST_Limbic  \\\n",
      "0   0.181050  0.321492  ...         NaN             NaN            NaN   \n",
      "1   0.198805  0.246843  ...   10.634176        8.717613       8.717613   \n",
      "2   0.263617  0.315452  ...   19.148896        6.671460       6.671460   \n",
      "3   0.281569  0.251389  ...    9.101265        5.085420       5.085420   \n",
      "4   0.217519  0.240696  ...   12.890636        7.613431       7.613431   \n",
      "..       ...       ...  ...         ...             ...            ...   \n",
      "87  0.202601  0.152275  ...    8.294054        7.859112       7.859112   \n",
      "88  0.309203  0.284672  ...    5.764124        5.996004       5.996004   \n",
      "89  0.186110  0.319345  ...         NaN             NaN            NaN   \n",
      "90  0.113230  0.294930  ...   12.444905        6.483539       6.483539   \n",
      "91  0.118364  0.253772  ...   11.527322        5.055306       5.055306   \n",
      "\n",
      "    avgCEST_SalVentAttn  ctCEST_SalVentAttn    tap_tot  volt_cr  volt_rtcr  \\\n",
      "0                   NaN                 NaN  123.66670     18.0     1296.0   \n",
      "1              7.569129            7.569129        NaN      NaN        NaN   \n",
      "2              8.770434            8.770434  112.66670     15.0     2027.0   \n",
      "3              7.394638            7.394638  115.33330     18.0     1556.0   \n",
      "4              8.303654            8.303654  117.66670     14.0     1521.0   \n",
      "..                  ...                 ...        ...      ...        ...   \n",
      "87             8.102914            8.102914  130.66670     19.0     1600.0   \n",
      "88             7.611919            7.611919  143.00000     13.0     1468.0   \n",
      "89                  NaN                 NaN   99.66667      NaN        NaN   \n",
      "90             8.551332            8.551332        NaN      NaN        NaN   \n",
      "91             8.467449            8.467449        NaN     20.0     1384.5   \n",
      "\n",
      "    hstatus   age  \n",
      "0         O  21.9  \n",
      "1       NaN  19.8  \n",
      "2       PRO  19.2  \n",
      "3       PSY  24.8  \n",
      "4       PRO  14.5  \n",
      "..      ...   ...  \n",
      "87      PRO  18.8  \n",
      "88      PSY  21.9  \n",
      "89        S  19.8  \n",
      "90      NaN  24.6  \n",
      "91      PRO  20.3  \n",
      "\n",
      "[92 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(grp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db63e65f-ea87-4a63-b66a-533be15b6ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(grp_df['avgCEST_SomMot'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7575f314-c5b4-4be1-87bd-5493fb6ff4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grp_df.to_csv('grp_df_3T_SOBP_wba_BG.csv', index=True)\n",
    "#diag_df.to_csv('diag_df_3T_SOBP_wba.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "611e0f79-7de7-4cd6-b193-a80adfa5f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df.to_csv('grp_df_3T.csv', index=True)\n",
    "diag_df.to_csv('diag_df_3T.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "387ace24-c2ab-4f50-8f20-00cfabd0b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grp_df = pd.read_csv('012624_grp_df_3T.csv')\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee3b975c-fb80-4e17-8f18-c8ccd16891c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook motor_pipeline.ipynb to html\n",
      "[NbConvertApp] Writing 1146801 bytes to motor_pipeline_3T.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html motor_pipeline.ipynb --output motor_pipeline_3T.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
