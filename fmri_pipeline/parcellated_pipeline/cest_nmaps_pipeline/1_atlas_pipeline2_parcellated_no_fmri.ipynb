{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549b8fc7",
   "metadata": {},
   "source": [
    "## Pipeline Script \n",
    "\n",
    "\n",
    "Inputs: Group CEST and nmap data output from pyGluCEST as well as demographic data from _________. \n",
    "Outputs: Compiled dataframes with GluCEST and nmap data. Trimmed based on number of people with sufficient data.\n",
    "\n",
    "    Trimmed subject-wise dfs: e.g., cestmat (outpath + 'trimmed_cestmat' + dataset + atlas + '.csv')\n",
    "    Long form dfs: e.g., long_df (outpath + 'longform_grpdf' + dataset + '_' + atlas + '.csv')\n",
    "         Also have version with standard nmap values\n",
    "    Mean dfs: e.g., grouped_df (outpath + 'means_' + dataset + '_' + atlas + '.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed04e7",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "18b02078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import network_fcon as fc\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nilearn.datasets import fetch_atlas_schaefer_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f51435",
   "metadata": {},
   "source": [
    "### Define paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d1c02784",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set variables\n",
    "dataset = 'longglucest_outputmeasures2'\n",
    "atlas = 'Schaefer2018_1000Parcels_17Networks'\n",
    "nmaps = [\"NMDA\", \"mGluR5\", \"GABA\"]\n",
    "maps = [\"cest\", \"NMDA\", \"mGluR5\", \"GABA\"]\n",
    "\n",
    "# Set paths\n",
    "inpath = \"/Users/pecsok/Desktop/ImageData/PMACS_remote/data/nmaps/\" + dataset\n",
    "outpath = \"/Users/pecsok/Desktop/ImageData/PMACS_remote/data/nmaps/analyses/\" + atlas\n",
    "\n",
    "# Read in data\n",
    "cestmat = pd.read_csv(inpath + \"/all_subs_GluCEST_\" + atlas + \"_UNI.csv\", sep=',')\n",
    "NMDAmat = pd.read_csv(inpath + \"/all_subs_NMDA_normalized_\" + atlas + \"_UNI.csv\", sep=',')\n",
    "mGluR5mat = pd.read_csv(inpath + \"/all_subs_mGluR5_normalized_\" + atlas + \"_UNI.csv\", sep=',')\n",
    "GABAmat = pd.read_csv(inpath + \"/all_subs_GABA_normalized_\" + atlas + \"_UNI.csv\", sep=',')\n",
    "\n",
    "# Set indices and correct column names\n",
    "cestmat.set_index('Subject', inplace = True)\n",
    "NMDAmat.set_index('Subject', inplace = True)\n",
    "GABAmat.set_index('Subject', inplace = True)\n",
    "mGluR5mat.set_index('Subject', inplace = True)\n",
    "dfs = [cestmat, NMDAmat, mGluR5mat, GABAmat]\n",
    "\n",
    "# Load in standardized nmap data for alternative approach.\n",
    "receptor_df = pd.read_csv(\"/Users/pecsok/projects/Neuromaps/pecsok_pfns/neuromaps/results/receptor_data_scale1000_17.csv\", sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0c2783-37dc-427b-906d-63bd2fde3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#print(grp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2359da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9cd53ddb-8695-4e2c-858c-337f97aaf531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 830)\n",
      "(176, 203)\n",
      "(172, 203)\n"
     ]
    }
   ],
   "source": [
    "# ID parcels with < 20 voxels* \n",
    "for i, col in enumerate(cestmat.columns):\n",
    "    if 'NZcount' in col:\n",
    "        # Set mean col to nan\n",
    "        mean_col = cestmat.columns[i - 1]\n",
    "        sigma_col = cestmat.columns[i + 1]\n",
    "        cestmat[mean_col] = np.where(cestmat[col] < 20, np.nan, cestmat[mean_col])\n",
    "        cestmat[sigma_col] = np.where(cestmat[col] < 20, np.nan, cestmat[sigma_col])\n",
    "        cestmat[col] = np.where(cestmat[col] < 20, np.nan, cestmat[col])       \n",
    "columns = cestmat.columns[cestmat.notnull().sum() > len(cestmat)*.75]\n",
    "print(cestmat.shape)\n",
    "\n",
    "# Trim all dfs based on column filter\n",
    "cestmat= cestmat[columns]\n",
    "NMDAmat= NMDAmat[columns]\n",
    "GABAmat= GABAmat[columns]\n",
    "mGluR5mat= mGluR5mat[columns]\n",
    "print(cestmat.shape)\n",
    "\n",
    "# ID subjects missing >65% of remaining GluCEST parcels\n",
    "sparse_subjs = cestmat[cestmat.isna().sum(axis=1) > cestmat.shape[1] * 0.65].index\n",
    "\n",
    "# Trim all dfs based on row filter\n",
    "cestmat = cestmat.drop(index=sparse_subjs)\n",
    "NMDAmat = NMDAmat.drop(index=sparse_subjs)\n",
    "GABAmat = GABAmat.drop(index=sparse_subjs)\n",
    "mGluR5mat = mGluR5mat.drop(index=sparse_subjs)\n",
    "print(cestmat.shape)\n",
    "\n",
    "#for df in dfs: Fix, put this back into a loop later\n",
    "#    df = df[columns]\n",
    "#    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3f760808-fe01-407c-b49c-86f7948a4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary: Remove mysterious zeros in nmap dataframes\n",
    "dfs = [NMDAmat, mGluR5mat, GABAmat]\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i]\n",
    "    df.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e0ec062a-ab46-47cc-9871-e8c26cb748ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trimmed dfs\n",
    "cestmat.to_csv(outpath + 'trimmed_cestmat' + dataset + atlas + '.csv', index=True)\n",
    "NMDAmat.to_csv(outpath + 'trimmed_NMDAmat' + dataset + atlas + '.csv', index=True)\n",
    "GABAmat.to_csv(outpath + 'trimmed_GABAmat' + dataset + atlas + '.csv', index=True)\n",
    "mGluR5mat.to_csv(outpath + 'trimmed_mGluR5mat' + dataset + atlas + '.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078fad84-4dde-4c48-b5b2-692cc6e77b4e",
   "metadata": {},
   "source": [
    "## Make longform group df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5d7f53be-f6eb-4a94-b84e-e9c51439c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Subject                                    Parcel   GluCEST  \\\n",
      "0      100522_12003    17Networks_RH_VisCent_Striate_2 NZMean       NaN   \n",
      "1      100522_12371    17Networks_RH_VisCent_Striate_2 NZMean       NaN   \n",
      "2      100522_12783    17Networks_RH_VisCent_Striate_2 NZMean       NaN   \n",
      "3      102041_12037    17Networks_RH_VisCent_Striate_2 NZMean  6.896060   \n",
      "4      102041_12500    17Networks_RH_VisCent_Striate_2 NZMean  9.101267   \n",
      "...             ...                                       ...       ...   \n",
      "11519   96902_11903  17Networks_RH_DefaultA_pCunPCC_12 NZMean  8.674353   \n",
      "11520   96902_12440  17Networks_RH_DefaultA_pCunPCC_12 NZMean       NaN   \n",
      "11521   96902_12788  17Networks_RH_DefaultA_pCunPCC_12 NZMean       NaN   \n",
      "11522   98370_12558  17Networks_RH_DefaultA_pCunPCC_12 NZMean  8.809414   \n",
      "11523   98370_12952  17Networks_RH_DefaultA_pCunPCC_12 NZMean  7.371335   \n",
      "\n",
      "           NMDA      GABA    mGluR5    group hstatus  \n",
      "0           NaN       NaN       NaN    TD/NC      HC  \n",
      "1           NaN       NaN       NaN    TD/NC      HC  \n",
      "2           NaN       NaN       NaN    TD/NC      HC  \n",
      "3     -0.037935  1.187287  0.103310  PRO/CHR     PSY  \n",
      "4     -0.143794  1.131643  0.024182  PRO/CHR     PSY  \n",
      "...         ...       ...       ...      ...     ...  \n",
      "11519       NaN       NaN       NaN    TD/NC      HC  \n",
      "11520       NaN       NaN       NaN    TD/NC      HC  \n",
      "11521       NaN       NaN       NaN    TD/NC      HC  \n",
      "11522  1.695410  1.988831  1.795521    TD/NC      HC  \n",
      "11523  1.602853  1.882797  1.762826    TD/NC      HC  \n",
      "\n",
      "[11524 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make longform group df\n",
    "# Get list of parcel names\n",
    "parcels = cestmat.filter(like=\"NZMean\").columns.tolist()\n",
    "\n",
    "# Melt cestmat to get Glu data in long format\n",
    "cestlong = cestmat.reset_index().melt(id_vars='Subject', value_vars=parcels, \n",
    "                                      var_name='Parcel', value_name='GluCEST')\n",
    "\n",
    "# Melt nmap data. Fix!! turn into loop later.\n",
    "NMDAlong = NMDAmat.reset_index().melt(id_vars='Subject', value_vars=parcels, \n",
    "                                       var_name='Parcel', value_name='NMDA')\n",
    "GABAlong = GABAmat.reset_index().melt(id_vars='Subject', value_vars=parcels, \n",
    "                                       var_name='Parcel', value_name='GABA')\n",
    "mGluR5long = mGluR5mat.reset_index().melt(id_vars='Subject', value_vars=parcels, \n",
    "                                       var_name='Parcel', value_name='mGluR5')\n",
    "\n",
    "# Merge the long-form dataframes based on Subject and Parcel\n",
    "long_df = pd.merge(cestlong, NMDAlong,  on=['Subject', 'Parcel'])\n",
    "long_df = pd.merge(long_df, GABAlong,  on=['Subject', 'Parcel'])\n",
    "long_df = pd.merge(long_df, mGluR5long,  on=['Subject', 'Parcel'])\n",
    "\n",
    "# Add diagnostic group\n",
    "diag_df = cestmat['group']\n",
    "long_df = pd.merge(long_df, diag_df, on='Subject')\n",
    "long_df['hstatus'] = np.where(long_df['group'].isin(['TD/NC']), 'HC', 'PSY')\n",
    "\n",
    "# Display the long-form dataframe\n",
    "print(long_df)\n",
    "\n",
    "# Save longformdf\n",
    "long_df.to_csv(outpath + '/longform_grpdf' + dataset + atlas + '.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91277b61-b9aa-4b9b-a389-ceffbcac1a8e",
   "metadata": {},
   "source": [
    "#### Repeat using standard nmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3b50140f-d244-4c15-954c-433283c7fbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     NMDA    mGluR5     GABAa        D2\n",
      "Parcel                                                                 \n",
      "17Networks_LH_VisCent_Striate_1  0.222071 -1.676590  0.454865 -1.793413\n",
      "17Networks_LH_VisCent_Striate_2 -0.498181 -1.582004  0.778041 -1.725353\n",
      "17Networks_LH_VisCent_Striate_3  0.901576 -0.612121  2.141349 -1.079382\n",
      "17Networks_LH_VisCent_Striate_4 -1.250976 -2.019832 -0.681790 -1.734788\n",
      "17Networks_LH_VisCent_ExStr_1    0.924391 -0.341650  0.853886  0.268522\n",
      "...                                   ...       ...       ...       ...\n",
      "17Networks_RH_TempPar_18         0.906115  0.748027  0.435516  0.148707\n",
      "17Networks_RH_TempPar_19        -0.093347  0.810461 -0.015695  0.217057\n",
      "17Networks_RH_TempPar_20         0.859066  0.746511  0.069180  0.635338\n",
      "17Networks_RH_TempPar_21         0.825170  1.057345  0.635444  0.371140\n",
      "17Networks_RH_TempPar_22         0.219509  1.022109  0.470702  0.717365\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import and add parcel labels to standard receptor_df\n",
    "schaefer = fetch_atlas_schaefer_2018(n_rois=1000, yeo_networks=17)\n",
    "labels = schaefer.labels\n",
    "labels = [label.decode('utf-8') for label in labels]\n",
    "receptor_df.index = labels\n",
    "receptor_df.index.name = 'Parcel'\n",
    "print(receptor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3e14bf1e-1a7c-431a-b517-4d69d25f49f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/w6xmtt2d55xfbxvb6wcqhq580000gp/T/ipykernel_6865/162084472.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  longdf_cest[\"Parcel\"] = longdf_cest[\"Parcel\"].str.replace(' NZMean', '', regex=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Subject                             Parcel   GluCEST    group  \\\n",
      "0      100522_12003    17Networks_RH_VisCent_Striate_2       NaN    TD/NC   \n",
      "1      100522_12371    17Networks_RH_VisCent_Striate_2       NaN    TD/NC   \n",
      "2      100522_12783    17Networks_RH_VisCent_Striate_2       NaN    TD/NC   \n",
      "3      102041_12037    17Networks_RH_VisCent_Striate_2  6.896060  PRO/CHR   \n",
      "4      102041_12500    17Networks_RH_VisCent_Striate_2  9.101267  PRO/CHR   \n",
      "...             ...                                ...       ...      ...   \n",
      "11519   96902_11903  17Networks_RH_DefaultA_pCunPCC_12  8.674353    TD/NC   \n",
      "11520   96902_12440  17Networks_RH_DefaultA_pCunPCC_12       NaN    TD/NC   \n",
      "11521   96902_12788  17Networks_RH_DefaultA_pCunPCC_12       NaN    TD/NC   \n",
      "11522   98370_12558  17Networks_RH_DefaultA_pCunPCC_12  8.809414    TD/NC   \n",
      "11523   98370_12952  17Networks_RH_DefaultA_pCunPCC_12  7.371335    TD/NC   \n",
      "\n",
      "      hstatus  NMDA_standard  GABA_standard  mGluR5_standard  \n",
      "0          HC       0.946837       2.481264        -0.377612  \n",
      "1          HC       0.946837       2.481264        -0.377612  \n",
      "2          HC       0.946837       2.481264        -0.377612  \n",
      "3         PSY       0.946837       2.481264        -0.377612  \n",
      "4         PSY       0.946837       2.481264        -0.377612  \n",
      "...       ...            ...            ...              ...  \n",
      "11519      HC       1.035005       0.225411         0.970607  \n",
      "11520      HC       1.035005       0.225411         0.970607  \n",
      "11521      HC       1.035005       0.225411         0.970607  \n",
      "11522      HC       1.035005       0.225411         0.970607  \n",
      "11523      HC       1.035005       0.225411         0.970607  \n",
      "\n",
      "[11524 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make longform df using standardized nmaps values\n",
    "\n",
    "# Get list of parcel names\n",
    "parcels = cestmat.filter(like=\"NZMean\").columns.tolist()\n",
    "\n",
    "# Keep relevant columns from long_df and rename parcels\n",
    "longdf_cest = long_df[[\"Subject\",\"Parcel\",\"GluCEST\",\"group\",\"hstatus\"]]\n",
    "longdf_cest[\"Parcel\"] = longdf_cest[\"Parcel\"].str.replace(' NZMean', '', regex=False)\n",
    "\n",
    "# Chop up receptor_df by map\n",
    "NMDAmat = receptor_df[\"NMDA\"]\n",
    "GABAmat = receptor_df[\"GABAa\"]\n",
    "mGluR5mat = receptor_df[\"mGluR5\"]\n",
    "\n",
    "# Convert receptor_df from wide to long format for merging\n",
    "nmda_long = NMDAmat.reset_index().melt(id_vars='Parcel', var_name='Receptor1', value_name='NMDA_standard')\n",
    "gaba_long = GABAmat.reset_index().melt(id_vars='Parcel', var_name='Receptor2', value_name='GABA_standard')\n",
    "mglur5_long = mGluR5mat.reset_index().melt(id_vars='Parcel', var_name='Receptor3', value_name='mGluR5_standard')\n",
    "\n",
    "# Combine dfs\n",
    "long_df_std = pd.merge(longdf_cest, nmda_long, on='Parcel', how='left')\n",
    "long_df_std = pd.merge(long_df_std, gaba_long, on='Parcel', how='left')\n",
    "long_df_std = pd.merge(long_df_std, mglur5_long, on='Parcel', how='left')\n",
    "# Remove unnecessary columns\n",
    "long_df_std = long_df_std.drop(columns=long_df_std.filter(like=\"Receptor\").columns)\n",
    "print(long_df_std)\n",
    "\n",
    "# Save the longform dataframe to a CSV\n",
    "long_df_std.to_csv(outpath + '/longform_grpdf_standardnmaps_' + dataset + '_' + atlas + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0f3aa290-06c8-4d5a-8f39-cb87f63332ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Parcel hstatus  GluCEST_avg  NMDA_avg  \\\n",
      "0         17Networks_RH_ContA_Cingm_1 NZMean      HC     7.348242 -0.515943   \n",
      "1         17Networks_RH_ContA_Cingm_1 NZMean     PSY     7.536327 -0.478070   \n",
      "2         17Networks_RH_ContA_Cingm_2 NZMean      HC     7.400822 -0.662924   \n",
      "3         17Networks_RH_ContA_Cingm_2 NZMean     PSY     7.629667 -0.608125   \n",
      "4         17Networks_RH_ContB_PFCmp_1 NZMean      HC     7.561262  0.665146   \n",
      "..                                       ...     ...          ...       ...   \n",
      "129  17Networks_RH_VisPeri_ExStrSup_7 NZMean     PSY     8.500733  0.819882   \n",
      "130   17Networks_RH_VisPeri_StriCal_3 NZMean      HC     9.569096 -0.013643   \n",
      "131   17Networks_RH_VisPeri_StriCal_3 NZMean     PSY     9.336277  0.003004   \n",
      "132   17Networks_RH_VisPeri_StriCal_5 NZMean      HC     9.077889  0.177231   \n",
      "133   17Networks_RH_VisPeri_StriCal_5 NZMean     PSY     9.030074  0.039007   \n",
      "\n",
      "     mGluR5_avg  GABA_avg  \n",
      "0     -0.290452 -0.823318  \n",
      "1     -0.286724 -0.835636  \n",
      "2     -0.352973 -0.831129  \n",
      "3     -0.341912 -0.837279  \n",
      "4      0.898630  0.642155  \n",
      "..          ...       ...  \n",
      "129    1.357389  1.698075  \n",
      "130    0.141399  1.371713  \n",
      "131    0.171412  1.413359  \n",
      "132    0.461898  1.570615  \n",
      "133    0.428818  1.501366  \n",
      "\n",
      "[134 rows x 6 columns]\n",
      "                               Parcel hstatus  GluCEST_avg  NMDA_avg  \\\n",
      "0         17Networks_RH_ContA_Cingm_1      HC     7.348242 -0.861131   \n",
      "1         17Networks_RH_ContA_Cingm_1     PSY     7.536327 -0.861131   \n",
      "2         17Networks_RH_ContA_Cingm_2      HC     7.400822 -0.970507   \n",
      "3         17Networks_RH_ContA_Cingm_2     PSY     7.629667 -0.970507   \n",
      "4         17Networks_RH_ContB_PFCmp_1      HC     7.561262  1.266783   \n",
      "..                                ...     ...          ...       ...   \n",
      "129  17Networks_RH_VisPeri_ExStrSup_7     PSY     8.500733  0.725344   \n",
      "130   17Networks_RH_VisPeri_StriCal_3      HC     9.569096  1.396886   \n",
      "131   17Networks_RH_VisPeri_StriCal_3     PSY     9.336277  1.396886   \n",
      "132   17Networks_RH_VisPeri_StriCal_5      HC     9.077889  1.191815   \n",
      "133   17Networks_RH_VisPeri_StriCal_5     PSY     9.030074  1.191815   \n",
      "\n",
      "     mGluR5_avg  GABA_avg  \n",
      "0     -1.573938 -0.950374  \n",
      "1     -1.573938 -0.950374  \n",
      "2     -1.450434 -0.850629  \n",
      "3     -1.450434 -0.850629  \n",
      "4      1.540954  0.854535  \n",
      "..          ...       ...  \n",
      "129    0.649158  1.166549  \n",
      "130   -0.190620  2.828990  \n",
      "131   -0.190620  2.828990  \n",
      "132   -0.072134  2.550402  \n",
      "133   -0.072134  2.550402  \n",
      "\n",
      "[134 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make mean group dfs by diagnosis\n",
    "# Subject-wise data\n",
    "grouped_df2 = long_df.groupby(['Parcel', 'hstatus']).agg(\n",
    "    GluCEST_avg=('GluCEST', 'mean'),\n",
    "    NMDA_avg=('NMDA', 'mean'),\n",
    "    mGluR5_avg=('mGluR5', 'mean'),\n",
    "    GABA_avg=('GABA', 'mean')\n",
    ").reset_index()\n",
    "print(grouped_df2)\n",
    "grouped_df2.to_csv(outpath + '/means_subjectnmaps_' + dataset + '_' + atlas + '.csv', index=False)\n",
    "\n",
    "# Standard nmap data\n",
    "grouped_df = long_df_std.groupby(['Parcel', 'hstatus']).agg(\n",
    "    GluCEST_avg=('GluCEST', 'mean'),\n",
    "    NMDA_avg=('NMDA_standard', 'mean'),\n",
    "    mGluR5_avg=('mGluR5_standard', 'mean'),\n",
    "    GABA_avg=('GABA_standard', 'mean')\n",
    ").reset_index()\n",
    "print(grouped_df)\n",
    "grouped_df.to_csv(outpath + '/means_standardnmaps_' + dataset + '_' + atlas + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75d829-4e24-4856-bec6-7d5ff8312dc6",
   "metadata": {},
   "source": [
    "### Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3229e558-bb52-466b-878e-0bd4ac378ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for the long_dfs, impute data based on average across participants for that parcel\n",
    "\n",
    "# Subject-wise data\n",
    "merged_df = pd.merge(long_df, grouped_df2[['Parcel', 'hstatus', 'GluCEST_avg']], on=['Parcel', 'hstatus'], how='left')\n",
    "merged_df['GluCEST'] = merged_df['GluCEST'].fillna(merged_df['GluCEST_avg'])\n",
    "#print(merged_df)\n",
    "imputed_df = merged_df.drop(columns=['GluCEST_avg'])\n",
    "\n",
    "# Standard data\n",
    "# First, rename parcels\n",
    "long_df_std[\"Parcel\"] = long_df_std[\"Parcel\"].str.replace(' NZMean', '', regex=False)\n",
    "#print(long_df_std)\n",
    "merged_df_std = pd.merge(long_df_std, grouped_df[['Parcel', 'hstatus', 'GluCEST_avg']], on=['Parcel', 'hstatus'], how='left')\n",
    "merged_df_std['GluCEST'] = merged_df_std ['GluCEST'].fillna(merged_df_std ['GluCEST_avg'])\n",
    "#print(merged_df_std)\n",
    "imputed_df_std = merged_df_std.drop(columns=['GluCEST_avg'])\n",
    "\n",
    "imputed_df.to_csv(outpath + '/imputed_long_df_' + dataset + '_' + atlas + '.csv', index=False)\n",
    "imputed_df_std.to_csv(outpath + '/imputed_long_df_standardnmaps_' + dataset + '_' + atlas + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
