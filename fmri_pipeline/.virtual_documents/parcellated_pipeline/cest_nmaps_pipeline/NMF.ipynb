





import os
import glob
import numpy as np
import pandas as pd
#import network_fcon as fc
import scipy as sp
from scipy.stats import pearsonr
from scipy.stats import linregress
import seaborn as sns
import matplotlib.pyplot as plt
import re
import seaborn as sns
import statsmodels.formula.api as smf
from sklearn.decomposition import NMF





# Set Variables
fieldstrength = '3T'
atlas = 'S1000'
bblids = []
sesids = []
nmaps = ["NMDA", "mGluR5", "GABA","D2"]
diag_scores = ["dx_pscat", "hstatus","sex", "age", "race","ethnic"] # ,"axis1_desc1","axis1_stat1"
diag_details = ["axis1_desc1", "axis1_desc2", "axis1_desc3","axis1_desc4","axis1_desc5", "axis1_desc6"]
#subjlist = subjlist[subjlist['fieldstrength'] == fieldstrength]
#subjs = subjlist['BBLID']

# Set paths
inpath = '/Users/pecsok/projects/GluCEST-fMRI/glucest-rsfmri/fmri_pipeline/parcellated_pipeline/'
outpath = '/Users/pecsok/projects/GluCEST-fMRI/glucest-rsfmri/fmri_pipeline/parcellated_pipeline/figures/' + atlas
print(outpath)
# Import group dataframes and set indices

#subjlist = pd.read_csv(path + "data/pipeline_input_all_subj.csv", sep=',') 
#cestmat = pd.read_csv("cest_parcelmat" + fieldstrength + atlas + ".csv", sep=',') 
cestmat = pd.read_csv(inpath + "filtered_cest_parcelmat" + fieldstrength + atlas + ".csv", sep=',') 
#fcmat = pd.read_csv(inpath + "fc_parcelmat_" + fieldstrength + atlas + ".csv", sep=',')
#rehomat = pd.read_csv(inpath + "reho_parcelmat" + fieldstrength + atlas + ".csv", sep=',')
grp_df = pd.read_csv(inpath + "filtered_grp_df" + fieldstrength + atlas + ".csv", sep=',')

# Reformat some dfs
cestmat.set_index('BBLID', inplace = True)
#fcmat.set_index('BBLID', inplace = True)
#rehomat.set_index('BBLID', inplace = True)
grp_df.set_index('BBLID', inplace = True)






def filter(df, filter_list):
    filtered_columns = [col for col in df.columns if not any(substring in col for substring in filter_list)]
    return df[filtered_columns]

def keep(df, keep_list):
    keep_columns = [col for col in df.columns if any(substring in col for substring in keep_list)]
    return df[keep_columns]   

def corr_sig(df=None):
    p_matrix = np.zeros(shape=(df.shape[1],df.shape[1]))
    for col in df.columns:
        for col2 in df.drop(col,axis=1).columns:
            valid_data = df[[col,col2]].dropna()
            if not valid_data.empty:
                _ , p = pearsonr(valid_data[col],valid_data[col2])
                p_matrix[df.columns.to_list().index(col),df.columns.to_list().index(col2)] = p
            else:
                p_matrix[df.columns.to_list().index(col),df.columns.to_list().index(col2)] = np.nan
    return p_matrix







# Filter df to exclude subj info
#subj_info = ["BBLID"] + ["Session"] + diag_scores + ["count"]
#heat_df = filter(grp_df, subj_info)
print(cestmat)


# Assuming `df` is your data frame with brain regions and GluCEST values
# Transpose if necessary: df = df.T
pd.set_option('display.max_rows', None)

cestmeans = keep(cestmat, ["NZMean"])


total_columns = cestmeans.shape[1]
cestmeans = cestmeans.dropna(thresh=total_columns - 30)
nan_counts = cestmeans.isna().sum(axis=0)
print(nan_counts)

data_matrix = cestmeans.values


# Apply NMF
k = 7
nmf = NMF(n_components=k, init='random', random_state=42)
W = nmf.fit_transform(data_matrix)  # Basis matrix (regions)
H = nmf.components_  # Coefficients matrix (subjects)

# Optionally convert back to DataFrame for easier interpretation
basis_matrix = pd.DataFrame(W, columns=[f'Component_{i+1}' for i in range(k)])
coefficients_matrix = pd.DataFrame(H, index=[f'Subject_{i+1}' for i in range(H.shape[0])])
