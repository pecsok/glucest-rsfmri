





import os
import glob
import numpy as np
import pandas as pd
#import network_fcon as fc
import scipy as sp
from scipy.stats import pearsonr
from scipy.stats import linregress
import seaborn as sns
import matplotlib.pyplot as plt
import re
import seaborn as sns
import statsmodels.formula.api as smf





# Set Variables
fieldstrength = '3T'
atlas = 'S1000'
bblids = []
sesids = []
nmaps = ["NMDA", "mGluR5", "GABA","D2"]
diag_scores = ["dx_pscat", "hstatus","sex", "age", "race","ethnic"] # ,"axis1_desc1","axis1_stat1"
diag_details = ["axis1_desc1", "axis1_desc2", "axis1_desc3","axis1_desc4","axis1_desc5", "axis1_desc6"]
#subjlist = subjlist[subjlist['fieldstrength'] == fieldstrength]
#subjs = subjlist['BBLID']

# Import group dataframes and set indices
#subjlist = pd.read_csv(path + "data/pipeline_input_all_subj.csv", sep=',') 
cestmat = pd.read_csv("cest_parcelmat" + fieldstrength + atlas + ".csv", sep=',') 
fcmat = pd.read_csv("fc_parcelmat_" + fieldstrength + atlas + ".csv", sep=',')
rehomat = pd.read_csv("reho_parcelmat" + fieldstrength + atlas + ".csv", sep=',')
grp_df = pd.read_csv("filtered_grp_df" + fieldstrength + atlas + ".csv", sep=',')

# Reformat some dfs
cestmat.set_index('BBLID', inplace = True)
fcmat.set_index('BBLID', inplace = True)
rehomat.set_index('BBLID', inplace = True)
grp_df.set_index('BBLID', inplace = True)






def filter(df, filter_list):
    filtered_columns = [col for col in df.columns if not any(substring in col for substring in filter_list)]
    return df[filtered_columns]

def keep(df, keep_list):
    keep_columns = [col for col in df.columns if any(substring in col for substring in keep_list)]
    return df[keep_columns]   

def corr_sig(df=None):
    p_matrix = np.zeros(shape=(df.shape[1],df.shape[1]))
    for col in df.columns:
        for col2 in df.drop(col,axis=1).columns:
            valid_data = df[[col,col2]].dropna()
            if not valid_data.empty:
                _ , p = pearsonr(valid_data[col],valid_data[col2])
                p_matrix[df.columns.to_list().index(col),df.columns.to_list().index(col2)] = p
            else:
                p_matrix[df.columns.to_list().index(col),df.columns.to_list().index(col2)] = np.nan
    return p_matrix





# Filter df to exclude subj info
subj_info = ["BBLID"] + ["Session"] + diag_scores + ["count"]
heat_df = filter(grp_df, subj_info)
print(grp_df)


# Correlation matrix
corr_df=heat_df.corr()
#plt.figure(figsize=(11,9))
#sns.heatmap(corr_df, annot=False, cmap='coolwarm',linewidth=0.7)
#plt.title('Glu-FC Heatmap\nGross network architecture emerges more strongly in fc+reho\nbut also evident in within-Glu correlations')
#plt.tick_params(axis='both', which='major', labelsize=10)
#plt.show()





#pvals = corr_sig(heat_df)
mask01 = np.invert(np.tril(pvals<0.01))
#mask001 = np.invert(np.tril(pvals<0.001))


#plt.figure(figsize=(11,9))
#sns.heatmap(corr_df, mask=mask01, annot=False, cmap='coolwarm',linewidth=0.7)
#plt.title('Glu-FC Heatmap\nwith a p value threshold of <0.001')
#plt.show()

#masked_cestcorr = cestcorr_df.where(pvals <= .0001)


# Correlation matrix GluCEST-GluCEST
cestcorr_df = corr_df.filter(like="NZ", axis=0).filter(like="fc", axis=1)
plt.figure(figsize=(11,9))
sns.heatmap(cestcorr_df, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-FC Heatmap\nGross network architecture emerges')
#plt.tick_params(axis='both', which='major', labelsize=10)
plt.show()





## CEST-FC Heat map with network boxes.

# List of parcel names (from the index/columns of your cestcorr_df)
parcel_names = cestcorr_df.index.tolist()

# Define the network numbers to search for
networks = {
    'Visual': [502, 567],
    'Somatomotor': [574, 613],
    'Dorsal Attention': [692, 712],
    'Salience': [750, 797],
    'Limbic': [807, 812 ],
    'Control': [855, 910],
    'Default': [926, 974]
    # Add other networks with their corresponding numbers
}

# Find the indices for each network
network_boundaries = []
for network, nums in networks.items():
    indices = [i for i, name in enumerate(parcel_names) if any(str(num) in name for num in nums)]
    if indices:
        network_boundaries.append((min(indices), max(indices)))

# Plot the heatmap
plt.figure(figsize=(11, 9))
sns.heatmap(cestcorr_df, mask=mask02, annot=False, cmap='coolwarm', linewidth=0.7)

# Draw the black boxes around network boundaries
for (start, end) in network_boundaries:
    plt.plot([start, end+1], [start, start], color='black', lw=2)  # Top line
    plt.plot([start, end+1], [end+1, end+1], color='black', lw=2)  # Bottom line
    plt.plot([start, start], [start, end+1], color='black', lw=2)  # Left line
    plt.plot([end+1, end+1], [start, end+1], color='black', lw=2)  # Right line

plt.title('Glu-FC Heatmap\nGross network architecture emerges')
plt.show()


# Correlation matrix GluCEST-GluCEST
cestcorr_df = corr_df.filter(like="NZ", axis=0).filter(like="NZ", axis=1)
plt.figure(figsize=(11,9))
sns.heatmap(cestcorr_df, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-FC Heatmap\nGross network architecture emerges')
#plt.tick_params(axis='both', which='major', labelsize=10)
plt.show()


# Correlation matrix GluCEST-GluCEST
cestcorr_df = corr_df.filter(like="NZ", axis=0).filter(like="NZ", axis=1)
print(cestcorr_df.shape)
plt.figure(figsize=(11,9))
sns.clustermap(cestcorr_df, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-FC Heatmap\nGross network architecture emerges')
#plt.tick_params(axis='both', which='major', labelsize=10)
plt.show()


## CEST-FC Heat map with network boxes.

# List of parcel names (from the index/columns of your cestcorr_df)
parcel_names = cestcorr_df.index.tolist()

# Define the network numbers to search for
networks = {
    'Visual': [502, 567],
    'Somatomotor': [574, 613],
    'Dorsal Attention': [692, 712],
    'Salience': [750, 797],
    'Limbic': [807, 812 ],
    'Control': [855, 910],
    'Default': [926, 974]
    # Add other networks with their corresponding numbers
}

# Find the indices for each network
network_boundaries = []
for network, nums in networks.items():
    indices = [i for i, name in enumerate(parcel_names) if any(str(num) in name for num in nums)]
    if indices:
        network_boundaries.append((min(indices), max(indices)))

# Plot the heatmap
plt.figure(figsize=(11, 9))
sns.heatmap(cestcorr_df, mask=mask02, annot=False, cmap='coolwarm',linewidth=0.7)

# Draw the black boxes around network boundaries
for (start, end) in network_boundaries:
    plt.plot([start, end+1], [start, start], color='black', lw=2)  # Top line
    plt.plot([start, end+1], [end+1, end+1], color='black', lw=2)  # Bottom line
    plt.plot([start, start], [start, end+1], color='black', lw=2)  # Left line
    plt.plot([end+1, end+1], [start, end+1], color='black', lw=2)  # Right line

plt.title('Glu-FC Heatmap\nGross network architecture emerges')
plt.show()





## Heat map with network boxes.

# Keep only signficant values
cestfc = corr_df.filter(like="NZ", axis=0).filter(like="fc", axis=1)
pvals = corr_sig(cestfc)
pvals
mask01 = np.invert(np.tril(pvals<0.01))
mask02 = np.invert(pvals<0.0000001)


plt.figure(figsize=(11,9))
sns.heatmap(cestcorr_df, mask=mask02, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-FC Heatmap\nwith a p value threshold of <0.01')
plt.show()



# List of parcel names (from the index/columns of your cestcorr_df)
parcel_names = cestcorr_df.index.tolist()

# Define the network numbers to search for
networks = {
    'Visual': [502, 567],
    'Somatomotor': [574, 613],
    'Dorsal Attention': [692, 712],
    'Salience': [750, 797],
    'Limbic': [807, 812 ],
    'Control': [855, 910],
    'Default': [926, 974]
    # Add other networks with their corresponding numbers
}

# Find the indices for each network
network_boundaries = []
for network, nums in networks.items():
    indices = [i for i, name in enumerate(parcel_names) if any(str(num) in name for num in nums)]
    if indices:
        network_boundaries.append((min(indices), max(indices)))

# Plot the heatmap
plt.figure(figsize=(11, 9))
sns.heatmap(cestcorr_df, annot=False, cmap='coolwarm', linewidth=0.7)

# Draw the black boxes around network boundaries
for (start, end) in network_boundaries:
    plt.plot([start, end+1], [start, start], color='black', lw=2)  # Top line
    plt.plot([start, end+1], [end+1, end+1], color='black', lw=2)  # Bottom line
    plt.plot([start, start], [start, end+1], color='black', lw=2)  # Left line
    plt.plot([end+1, end+1], [start, end+1], color='black', lw=2)  # Right line

plt.title('Glu-FC Heatmap\nGross network architecture emerges')
plt.show()





def within_between(corr_df, parcels,symmetric):
    # Returns average correlation within and between network.
    ins = []
    outs = []
    for row in corr_df.index:
        for col in corr_df.columns:
            # Within-network: row and column have to contain parcel names
            if any(parcel in row for parcel in parcels) and any(parcel in col for parcel in parcels):
                if not pd.isna(corr_df.loc[row, col]):
                    ins.append(corr_df.loc[row, col])
                    
            # Between-network: Only row contains parcel name
            elif any(parcel in row for parcel in parcels) and not any(parcel in col for parcel in parcels):
                if not pd.isna(corr_df.loc[row, col]):
                    outs.append(corr_df.loc[row, col])
            if symmetric == False: # Only run columns with parcel name if corr_df is asymmetric
                if not any(parcel in row for parcel in parcels) and any(parcel in col for parcel in parcels):
                    if not pd.isna(corr_df.loc[row, col]):
                        outs.append(corr_df.loc[row, col])
    # Run t test comparing within- vs between-network values
    t, p = sp.stats.ttest_ind(ins,outs)
    # Take avg.
    avgin = np.mean(ins)
    sdin = np.std(ins)
    avgout = np.mean(outs)
    sdout = np.std(outs)
    return (avgin, sdin, avgout, sdout, t,p) 

vis = [str(x) for x in range(500,569)]
mn = [str(x) for x in range(569,659)]
da = [str(x) for x in range(659,721)]
sn = [str(x) for x in range(721,798)]
lim = [str(x) for x in range(798,829)]
ecn = [str(x) for x in range(829,911)]
dmn = [str(x) for x in range(911,980)]


masked_cestcorr = cestcorr_df.where(pvals <= .0001)

cestdf = pd.DataFrame(zip(
    within_between(cestcorr_df, vis, True),
    within_between(cestcorr_df, mn, True),
    within_between(cestcorr_df, da, True),
    within_between(cestcorr_df, sn, True),
    within_between(cestcorr_df, lim, True),
    within_between(cestcorr_df, ecn, True),
    within_between(cestcorr_df, dmn, True)),
                          columns = ["Vis","SomMot","DorsAttn","Sal","Limbic","Cont","Default"])
                       
cestdf.index = ["Within_avg", "Within_sd", "Between_avg","Between_sd","t","p"]
cestdf 


masked_cestcorr = cestcorr_df.where(pvals <= .0001)

cestdf = pd.DataFrame(zip(
    within_between(masked_cestcorr, vis, True),
    within_between(masked_cestcorr, mn, True),
    within_between(masked_cestcorr, da, True),
    within_between(masked_cestcorr, sn, True),
    within_between(masked_cestcorr, lim, True),
    within_between(masked_cestcorr, ecn, True),
    within_between(masked_cestcorr, dmn, True)),
                          columns = ["Vis","SomMot","DorsAttn","Sal","Limbic","Cont","Default"])
                       
cestdf.index = ["Within_avg", "Within_sd", "Between_avg","Between_sd","t","p"]
cestdf 


fcdf = pd.DataFrame(zip(
    within_between(cestfc, vis, True),
    within_between(cestfc, mn, True),
    within_between(cestfc, da, True),
    within_between(cestfc, sn, True),
    within_between(cestfc, lim, True),
    within_between(cestfc, ecn, True),
    within_between(cestfc, dmn, True)),
                          columns = ["Vis","SomMot","DorsAttn","Sal","Limbic","Cont","Default"])
                       
fcdf.index = ["Within_avg", "Within_sd", "Between_avg","Between_sd","t","p"]
fcdf 


# Make a bar plot comparing within vs between values.
# Extract values
df = cestdf
regions = df.columns
within_avg = df.loc['Within_avg']
within_sd = df.loc['Within_sd']
between_avg = df.loc['Between_avg']
between_sd = df.loc['Between_sd']

# Set positions and width for bars
n = 85 


x = np.arange(len(regions))
width = 0.35

within_se = within_sd / np.sqrt(n)
between_se = between_sd / np.sqrt(n)

# Create plot
fig, ax = plt.subplots(figsize=(10, 6))

# Plot within and between averages with error bars
#ax.bar(x - width/2, within_avg, width, yerr=within_sd, label='Within_avg', capsize=5, color='lightblue')
#ax.bar(x + width/2, between_avg, width, yerr=between_sd, label='Between_avg', capsize=5,color='salmon')
ax.bar(x - width/2, within_avg, width, yerr=within_se, label='Within_avg', capsize=5, color='lightblue')
ax.bar(x + width/2, between_avg, width, yerr=between_se, label='Between_avg', capsize=5, color='salmon')


# Set labels and title
ax.set_xlabel('Region')
ax.set_ylabel('Values')
ax.set_title('Within and Between Average Values with Error Bars by Region')
ax.set_xticks(x)
ax.set_xticklabels(regions)
ax.legend()

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Adjust layout and show plot
plt.tight_layout()
plt.show()





# Read in nmap data 
nmapsdf = pd.read_csv("receptor_data_scale1000_17.csv", sep=',', header=None)
#nmapsdf.columns = nmaps 

# Trim cestmat and keep only the columns with avg values.
cestNZMeans = keep(grp_df, ["NZMean"])
cestavgs = cestNZMeans.mean(axis=0)
# Make new df to store avg nmap values and average CEST values.
glunmaps = nmapsdf.copy()
glunmaps.index = range(1,1001)
glunmaps["CESTavg"] = np.nan
# Add values to new df
for i in range(501,1001):
    cestparcel = f'NZMean_{i}'
    if cestparcel in cestavgs.index:
        #print(cestparcel)
        #print(cestavgs[cestparcel])
        glunmaps.loc[i,"CESTavg"] = cestavgs[cestparcel]
glunmaps = glunmaps.dropna(subset=["CESTavg"])


sorted_df = glunmaps.sort_values(by="CESTavg", ascending=False)  # Use ascending=True if you want to sort in ascending order

print(sorted_df)


# Loop through nmaps and make correlation plots
# @Maggie, add color by SA axis value.
for nmap in nmaps:
    formula = f'CESTavg ~ {nmap}'
    rval, pval = pearsonr(glunmaps[nmap],glunmaps["CESTavg"])
    print(nmap)
    print("r=" + str(rval)," p=" + str(pval))

for nmap in nmaps:
    plot = sns.lmplot(x=nmap, y='CESTavg', data=glunmaps)
    plt.xlabel(nmap)
    plt.ylabel("CESTavg")
    #slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', network], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
    #plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    # Generate and add slope, r2 and p for subset 2
    #slope, intercept, r_value, p_value, std_err = linregress(graph_df[network], graph_df[cestcol])
    #plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    
    plt.title('Linear Regression between ' + nmap + ' and CEST')
    plt.show() 






import statsmodels.api as sm

x=glunmaps[nmaps]
y=glunmaps["CESTavg"]
x = sm.add_constant(x)
model = sm.OLS(y, x).fit()
print(model.summary())






from itertools import repeat 
# Read in nmap data 
nmapsdf = pd.read_csv("/Users/pecsok/projects/Neuromaps/pecsok_pfns/neuromaps/results/receptor_data_scale1000_17.csv", sep=',')
#nmapsdf.columns = nmaps 
print(nmapsdf)
nmapsdf.index = range(1,1001)


# Trim cestmat and keep only the columns with avg values.
df = keep(grp_df, (["NZMean", "hstatus"]))
NC_cestNZMeans = df.loc[:, (df.columns.str.contains("NZMean"))]
NCcestavgs = df[df["hstatus"] == "NC"].filter(like="NZMean").mean(axis=0)
PScestavgs = df[df["hstatus"] != "NC"].filter(like="NZMean").mean(axis=0)
parcels = df.filter(like="NZMean").columns.tolist()


cestdf = pd.DataFrame(
    zip(
        list(repeat("HC", len(NCcestavgs))) + list(repeat("Psy", len(PScestavgs))),  # Repeat "NC" and "PS"
        parcels + parcels,  # Parcel names repeated for both NC and PS
        np.concatenate([NCcestavgs.values, PScestavgs.values]),
        list(repeat("NaN", len(NCcestavgs))) + list(repeat("NaN", len(PScestavgs))),
        list(repeat("NaN", len(NCcestavgs))) + list(repeat("NaN", len(PScestavgs))),
        list(repeat("NaN", len(NCcestavgs))) + list(repeat("NaN", len(PScestavgs)))
    ),  # Concatenate the values for NC and PS
        #np.concatenate([nmap_NC_parcel_values, nmap_PS_parcel_values])  # Concatenate nmap parcel values  
    columns=["hstatus", "parcel", "CESTavg",'mGluR5', 'NMDA', 'GABA']
)

for nmap in nmaps:
    for i in range(501,1001):
        parcel = "NZMean_" + str(i) 
        if parcel in cestdf["parcel"].values:
            cestdf.loc[cestdf["parcel"] == parcel, nmap] = nmapsdf.loc[i, nmap]          

cestdf


# Trim cestmat and keep only the columns with avg values.
df = keep(grp_df, (["NZMean", "hstatus"]))
#NC_cestNZMeans = df.loc[:, (df.columns.str.contains("NZMean"))]
NCcestavgs = df[df["hstatus"] == "NC"].filter(like="NZMean").mean(axis=0)
PScestavgs = df[df["hstatus"] != "NC"].filter(like="NZMean").mean(axis=0)
parcels = df.filter(like="NZMean").columns.tolist()
cestavgs = df.filter(like="NZMean").mean(axis=0)
print(cestavgs)

cestdf = pd.DataFrame(
    zip(
        list(repeat("HC", len(NCcestavgs))) + list(repeat("Psy", len(PScestavgs))),  # Repeat "NC" and "PS"
        parcels + parcels,  # Parcel names repeated for both NC and PS
        np.concatenate([NCcestavgs.values, PScestavgs.values]),
        list(repeat("NaN", len(NCcestavgs))) + list(repeat("NaN", len(PScestavgs))),
        list(repeat("NaN", len(NCcestavgs))) + list(repeat("NaN", len(PScestavgs))),
        list(repeat("NaN", len(NCcestavgs))) + list(repeat("NaN", len(PScestavgs)))
    ),  # Concatenate the values for NC and PS
        #np.concatenate([nmap_NC_parcel_values, nmap_PS_parcel_values])  # Concatenate nmap parcel values  
    columns=["hstatus", "parcel", "CESTavg",'mGluR5', 'NMDA', 'GABA']
)

for nmap in nmaps:
    for i in range(501,1001):
        parcel = "NZMean_" + str(i) 
        if parcel in cestdf["parcel"].values:
            cestdf.loc[cestdf["parcel"] == parcel, nmap] = nmapsdf.loc[i, nmap]          

cestdf





# Loop through nmaps and make correlation plots
#print(cestdf[CESTavg].max())

nmap_palette = {
    "NMDA": "Purples",   # Replace with actual nmap names and desired palettes
    "mGluR5": "Reds",
    "GABA": "Greens",
    "D2": "Oranges"
    # Add more mappings as needed
}

for nmap in nmaps:
    cestdf[nmap] = pd.to_numeric(cestdf[nmap], errors='coerce')
    cestdf['CESTavg'] = pd.to_numeric(cestdf['CESTavg'], errors='coerce')
    plot_data = cestdf.dropna(subset=[nmap, 'CESTavg'])
    palette = nmap_palette.get(nmap) # Default to "Set1" if nmap not in dictionary
    plot = sns.lmplot(x=nmap, y='CESTavg', hue='hstatus', data=plot_data, palette=palette)
    plt.xlabel(nmap)
    plt.ylabel("CESTavg")
    plt.title('Linear Regression between ' + nmap + ' and CEST')
    plt.show() 



for nmap in nmaps:
    for group in ["Psy","HC"]:
        graphdf = cestdf[cestdf["hstatus"]==group]
        formula = f'CESTavg ~ {nmap}'
        rval, pval = pearsonr(graphdf[nmap],graphdf["CESTavg"])
        print(nmap)
        print("r=" + str(rval)," p=" + str(pval))



from scipy.stats import spearmanr

for nmap in nmaps:
    for group in ["Psy","HC"]:
        graphdf = cestdf[cestdf["hstatus"]==group]
        formula = f'CESTavg ~ {nmap}'
        rval, pval = spearmanr(graphdf[nmap],graphdf["CESTavg"])
        print(nmap)
        print("r=" + str(rval)," p=" + str(pval))



# Excluding visual network

vis = [str(x) for x in range(500,569)]
network_dict = {
    'VIS': vis
}

for nmap in nmaps:
    for network_name, parcel_range in network_dict.items():
        
        graphdf = cestdf[~cestdf['parcel'].str.extract('(\d+)')[0].isin(parcel_range)]
        #print(graphdf)
        #cestdf[cestdf['parcel'].str.extract('(\d+)').astype(float).between(500, 510)]
        graphdf[nmap] = pd.to_numeric(graphdf[nmap], errors='coerce')
        graphdf['CESTavg'] = pd.to_numeric(graphdf['CESTavg']) #, errors='coerce'
        plot_data = graphdf.dropna(subset=[nmap, 'CESTavg'])
        palette = nmap_palette.get(nmap) # Default to "Set1" if nmap not in dictionary
        plot = sns.lmplot(x=nmap, y='CESTavg', hue='hstatus', data=plot_data, palette=palette)
        plt.xlabel(nmap)
        plt.ylabel("CESTavg")
        plt.title('Linear Regression between ' + nmap + ' and CEST not including ' + network_name)
        plt.show() 

        #for nmap in nmaps:
        #for group in ["Psy","HC"]:
        #graphdf = cestdf[cestdf["hstatus"]==group]
        formula = f'CESTavg ~ {nmap}'
        rval, pval = pearsonr(graphdf[nmap],graphdf["CESTavg"])
        print(nmap)
        print("r=" + str(rval)," p=" + str(pval))







# Loop through nmaps and make correlation plots
#print(cestdf[CESTavg].max())


nmap_palette = {
    "NMDA": "Purples",   # Replace with actual nmap names and desired palettes
    "mGluR5": "Reds",
    "GABA": "Greens",
    "D2": "Oranges"
    # Add more mappings as needed
}



vis = [str(x) for x in range(500,569)]
mn = [str(x) for x in range(569,659)]
da = [str(x) for x in range(659,721)]
sn = [str(x) for x in range(721,798)]
lim = [str(x) for x in range(798,829)]
ecn = [str(x) for x in range(829,911)]
dmn = [str(x) for x in range(911,980)]

network_dict = {
    'VIS': vis,
    'MN': mn,
    'DA': da,
    'SN': sn,
    'LIM': lim,
    'ECN': ecn,
    'DMN': dmn
}



print(grp_df)
cestdata = grp_df.filter(like="NZ", axis=1).filter(like="fc", axis=1)

for nmap in nmaps:
    for network_name, parcel_range in network_dict.items():
        graphdf = cestdf[cestdf['parcel'].str.extract('(\d+)')[0].isin(parcel_range)]
        #print(graphdf)
        #cestdf[cestdf['parcel'].str.extract('(\d+)').astype(float).between(500, 510)]
        graphdf[nmap] = pd.to_numeric(graphdf[nmap], errors='coerce')
        graphdf['CESTavg'] = pd.to_numeric(graphdf['CESTavg']) #, errors='coerce'
        plot_data = graphdf.dropna(subset=[nmap, 'CESTavg'])
        palette = nmap_palette.get(nmap) # Default to "Set1" if nmap not in dictionary
        plot = sns.lmplot(x=nmap, y='CESTavg', hue='hstatus', data=plot_data, palette=palette)
        plt.xlabel(nmap)
        plt.ylabel("CESTavg")
        plt.title('Linear Regression between ' + nmap + ' and CEST within ' + network_name)
        plt.show() 



# Loop through nmaps and make correlation plots
#print(cestdf[CESTavg].max())


nmap_palette = {
    "NMDA": "Purples",   # Replace with actual nmap names and desired palettes
    "mGluR5": "Reds",
    "GABA": "Greens",
    "D2": "Oranges"
    # Add more mappings as needed
}



vis = [str(x) for x in range(500,569)]
mn = [str(x) for x in range(569,659)]
da = [str(x) for x in range(659,721)]
sn = [str(x) for x in range(721,798)]
lim = [str(x) for x in range(798,829)]
ecn = [str(x) for x in range(829,911)]
dmn = [str(x) for x in range(911,980)]

network_dict = {
    'VIS': vis,
    'MN': mn,
    'DA': da,
    'SN': sn,
    'LIM': lim,
    'ECN': ecn,
    'DMN': dmn
}

print(cestdf)
for nmap in nmaps:
    for network_name, parcel_range in network_dict.items():
        graphdf = cestdf[cestdf['parcel'].str.extract('(\d+)')[0].isin(parcel_range)]
        #print(graphdf)
        #cestdf[cestdf['parcel'].str.extract('(\d+)').astype(float).between(500, 510)]
        graphdf[nmap] = pd.to_numeric(graphdf[nmap], errors='coerce')
        graphdf['CESTavg'] = pd.to_numeric(graphdf['CESTavg']) #, errors='coerce'
        plot_data = graphdf.dropna(subset=[nmap, 'CESTavg'])
        palette = nmap_palette.get(nmap) # Default to "Set1" if nmap not in dictionary
        plot = sns.lmplot(x=nmap, y='CESTavg', hue='hstatus', data=plot_data, palette=palette)
        plt.xlabel(nmap)
        plt.ylabel("CESTavg")
        plt.title('Linear Regression between ' + nmap + ' and CEST within ' + network_name)
        plt.show() 
