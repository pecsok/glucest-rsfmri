





import os
import glob
import numpy as np
import pandas as pd
#import network_fcon as fc
import scipy as sp
from scipy.stats import pearsonr
from scipy.stats import linregress
import seaborn as sns
import matplotlib.pyplot as plt
import re
import seaborn as sns
import statsmodels.formula.api as smf





# Set Variables
fieldstrength = '3T'
atlas = 'S100'
bblids = []
sesids = []
nmaps = ["mGluR5", "NMDA","GABA"]
diag_scores = ["dx_pscat", "hstatus","sex", "age", "race","ethnic"] # ,"axis1_desc1","axis1_stat1"
diag_details = ["axis1_desc1", "axis1_desc2", "axis1_desc3","axis1_desc4","axis1_desc5", "axis1_desc6"]
#subjlist = subjlist[subjlist['fieldstrength'] == fieldstrength]
#subjs = subjlist['BBLID']

# Import group dataframes and set indices
#subjlist = pd.read_csv(path + "data/pipeline_input_all_subj.csv", sep=',') 
cestmat = pd.read_csv("cest_parcelmat" + fieldstrength + atlas + ".csv", sep=',') 
fcmat = pd.read_csv("fc_parcelmat_" + fieldstrength + atlas + ".csv", sep=',')
rehomat = pd.read_csv("reho_parcelmat" + fieldstrength + atlas + ".csv", sep=',')
grp_df = pd.read_csv("filtered_grp_df" + fieldstrength + atlas + ".csv", sep=',')

# Reformat some dfs
cestmat.set_index('BBLID', inplace = True)
fcmat.set_index('BBLID', inplace = True)
rehomat.set_index('BBLID', inplace = True)
grp_df.set_index('BBLID', inplace = True)






def filter(df, filter_list):
    filtered_columns = [col for col in df.columns if not any(substring in col for substring in filter_list)]
    return df[filtered_columns]

def keep(df, keep_list):
    keep_columns = [col for col in df.columns if any(substring in col for substring in keep_list)]
    return df[keep_columns]   

def corr_sig(df=None):
    p_matrix = np.zeros(shape=(df.shape[1],df.shape[1]))
    for col in df.columns:
        for col2 in df.drop(col,axis=1).columns:
            valid_data = df[[col,col2]].dropna()
            if not valid_data.empty:
                _ , p = pearsonr(valid_data[col],valid_data[col2])
                p_matrix[df.columns.to_list().index(col),df.columns.to_list().index(col2)] = p
            else:
                p_matrix[df.columns.to_list().index(col),df.columns.to_list().index(col2)] = np.nan
    return p_matrix





# Filter df to exclude subj info
subj_info = ["BBLID"] + ["Session"] + diag_scores + ["count"]
heat_df = filter(grp_df, subj_info)
print(heat_df)





corr_df=heat_df.corr()
#pvals = corr_sig(heat_df)
#mask01 = np.invert(np.tril(pvals<0.01))
#mask001 = np.invert(np.tril(pvals<0.001))


# Correlation matrix GluCEST-GluCEST
cestcorr_df = corr_df.filter(like="NZ", axis=0).filter(like="fc", axis=1)
plt.figure(figsize=(11,9))
sns.heatmap(cestcorr_df, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-FC Heatmap\nGross network architecture emerges')
#plt.tick_params(axis='both', which='major', labelsize=10)
plt.show()


# Keep only signficant values
cestfc = corr_df.filter(like="NZ", axis=0).filter(like="fc", axis=1)
pvals = corr_sig(cestfc)
pvals
mask01 = np.invert(np.tril(pvals<0.01))
mask02 = np.invert(pvals<0.0000001)


plt.figure(figsize=(11,9))
sns.heatmap(cestcorr_df, mask=mask02, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-FC Heatmap\nwith a p value threshold of <0.01')
plt.show()


# Correlation matrix GluCEST-GluCEST
cestcorr_df = corr_df.filter(like="NZ", axis=0).filter(like="NZ", axis=1)
plt.figure(figsize=(11,9))
sns.heatmap(cestcorr_df, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-FC Heatmap\nGross network architecture emerges')
#plt.tick_params(axis='both', which='major', labelsize=10)
plt.show()


# Keep only signficant values
pvals = corr_sig(cestcorr_df) #

#cestpvals = cestcorr_df.filter(like="NZ", axis=0).filter(like="NZ", axis=1)
mask01 = np.invert(np.tril(pvals<0.01))
mask02 = np.invert(pvals<0.00001)

plt.figure(figsize=(11,9))
sns.heatmap(cestcorr_df, mask=mask02, annot=False, cmap='coolwarm',linewidth=0.7)
plt.title('Glu-Glu Heatmap\nwith a p value threshold of <0.00001')
plt.show()


### Within- vs between-network


def within_between(corr_df, parcels,symmetric):
    # Returns average correlation within and between network.
    ins = []
    outs = []
    for row in corr_df.index:
        for col in corr_df.columns:
            # Within-network: row and column have to contain parcel names
            if any(parcel in row for parcel in parcels) and any(parcel in col for parcel in parcels):
                if not pd.isna(corr_df.loc[row, col]):
                    ins.append(corr_df.loc[row, col])
                    
            # Between-network: Only row contains parcel name
            elif any(parcel in row for parcel in parcels) and not any(parcel in col for parcel in parcels):
                if not pd.isna(corr_df.loc[row, col]):
                    outs.append(corr_df.loc[row, col])
            if symmetric == False: # Only run columns with parcel name if corr_df is asymmetric
                if not any(parcel in row for parcel in parcels) and any(parcel in col for parcel in parcels):
                    if not pd.isna(corr_df.loc[row, col]):
                        outs.append(corr_df.loc[row, col])
    # Run t test comparing within- vs between-network values
    t, p = sp.stats.ttest_ind(ins,outs)
    # Take avg.
    avgin = np.mean(ins)
    sdin = np.std(ins)
    avgout = np.mean(outs)
    sdout = np.std(outs)
    return (avgin, sdin, avgout, sdout, t,p) 

vis = [str(x) for x in range(500,569)]
mn = [str(x) for x in range(569,659)]
da = [str(x) for x in range(659,721)]
sn = [str(x) for x in range(721,798)]
lim = [str(x) for x in range(798,829)]
ecn = [str(x) for x in range(829,911)]
dmn = [str(x) for x in range(911,980)]


masked_cestcorr = cestcorr_df.where(pvals <= .0001)

cestdf = pd.DataFrame(zip(
    within_between(cestcorr_df, vis, True),
    within_between(cestcorr_df, mn, True),
    within_between(cestcorr_df, da, True),
    within_between(cestcorr_df, sn, True),
    within_between(cestcorr_df, lim, True),
    within_between(cestcorr_df, ecn, True),
    within_between(cestcorr_df, dmn, True)),
                          columns = ["Vis","SomMot","DorsAttn","Sal","Limbic","Cont","Default"])
                       
cestdf.index = ["Within_avg", "Within_sd", "Between_avg","Between_sd","t","p"]
cestdf 


masked_cestcorr = cestcorr_df.where(pvals <= .0001)

cestdf = pd.DataFrame(zip(
    within_between(masked_cestcorr, vis, True),
    within_between(masked_cestcorr, mn, True),
    within_between(masked_cestcorr, da, True),
    within_between(masked_cestcorr, sn, True),
    within_between(masked_cestcorr, lim, True),
    within_between(masked_cestcorr, ecn, True),
    within_between(masked_cestcorr, dmn, True)),
                          columns = ["Vis","SomMot","DorsAttn","Sal","Limbic","Cont","Default"])
                       
cestdf.index = ["Within_avg", "Within_sd", "Between_avg","Between_sd","t","p"]
cestdf 


fcdf = pd.DataFrame(zip(
    within_between(cestfc, vis, True),
    within_between(cestfc, mn, True),
    within_between(cestfc, da, True),
    within_between(cestfc, sn, True),
    within_between(cestfc, lim, True),
    within_between(cestfc, ecn, True),
    within_between(cestfc, dmn, True)),
                          columns = ["Vis","SomMot","DorsAttn","Sal","Limbic","Cont","Default"])
                       
fcdf.index = ["Within_avg", "Within_sd", "Between_avg","Between_sd","t","p"]
fcdf 


# Make a bar plot comparing within vs between values.
# Extract values
df = cestdf
regions = df.columns
within_avg = df.loc['Within_avg']
within_sd = df.loc['Within_sd']
between_avg = df.loc['Between_avg']
between_sd = df.loc['Between_sd']

# Set positions and width for bars
x = np.arange(len(regions))
width = 0.35

# Create plot
fig, ax = plt.subplots(figsize=(10, 6))

# Plot within and between averages with error bars
ax.bar(x - width/2, within_avg, width, yerr=within_sd, label='Within_avg', capsize=5, color='lightblue')
ax.bar(x + width/2, between_avg, width, yerr=between_sd, label='Between_avg', capsize=5,color='salmon')

# Set labels and title
ax.set_xlabel('Region')
ax.set_ylabel('Values')
ax.set_title('Within and Between Average Values with Error Bars by Region')
ax.set_xticks(x)
ax.set_xticklabels(regions)
ax.legend()

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Adjust layout and show plot
plt.tight_layout()
plt.show()





# Read in nmap data 
nmapsdf = pd.read_csv("receptor_data_scale1000_17.csv", sep=',', header=None)
nmapsdf.columns = nmaps 

# Trim cestmat and keep only the columns with avg values.
cestNZMeans = keep(grp_df, ["NZMean"])
#print(cestNZMeans)
cestavgs = cestNZMeans.mean(axis=0)
# Make new df to store avg nmap values and average CEST values.
glunmaps = nmapsdf.copy()
glunmaps.index = range(1,1001)
glunmaps["CESTavg"] = np.nan
# Add values to new df
for i in range(501,1001):
    cestparcel = f'NZMean_{i}'
    if cestparcel in cestavgs.index:
        #print(cestparcel)
        #print(cestavgs[cestparcel])
        glunmaps.loc[i,"CESTavg"] = cestavgs[cestparcel]
glunmaps = glunmaps.dropna(subset=["CESTavg"])


# Loop through nmaps and make correlation plots
# @Maggie, add color by SA axis value.
for nmap in nmaps:
    formula = f'CESTavg ~ {nmap}'
    rval, pval = pearsonr(glunmaps[nmap],glunmaps["CESTavg"])
    print(nmap)
    print("r=" + str(rval)," p=" + str(pval))

for nmap in nmaps:
    plot = sns.lmplot(x=nmap, y='CESTavg', data=glunmaps)
    plt.xlabel(nmap)
    plt.ylabel("CESTavg")
    #slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', network], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
    #plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    # Generate and add slope, r2 and p for subset 2
    #slope, intercept, r_value, p_value, std_err = linregress(graph_df[network], graph_df[cestcol])
    #plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    
    plt.title('Linear Regression between ' + nmap + ' and CEST')
    plt.show() 



import statsmodels.api as sm

x=glunmaps[nmaps]
y=glunmaps["CESTavg"]
x = sm.add_constant(x)
model = sm.OLS(y, x).fit()
print(model.summary())



# @Maggie, this is a temporary chunk. Move this to the end of the pipeline_parcellated script.
columns = cestmat.columns[cestmat.notnull().sum() > len(cestmat)*.75]
parcels = [col.split('_')[1] for col in columns if '_' in col]

unique_list = list(set(parcels))
seen = set()
unique_list = [x for x in parcels if not 
               (x in seen or seen.add(x))]
parcels = unique_list
print(parcels)


receptor_names = np.array(["NMDA","mGluR5","GABAa"])
np.save(path+'data/receptor_names_pet.npy', receptor_names)

# make final region x receptor matrix
receptor_data = np.zeros([nnodes, len(receptor_names)])


# NMDA Data
receptor_data[:, 0] = r[:, 0]


# plot each receptor map
if scale == 'scale1000_17':
    annot = datasets.fetch_schaefer2018('fsaverage')['1000Parcels17Networks']
    type(annot)
    print(annot)
    
    for k in range(len(receptor_names)):
        brain = plotting.plot_fsaverage(data=receptor_data[:, k],
                                        lhannot=annot.lh,
                                        rhannot=annot.rh,
                                        colormap='plasma',
                                        views=['lat', 'med'],
                                        data_kws={'representation': "wireframe"})
        brain.save_image(path+'figures/scale1000_17/surface_receptor_'+receptor_names[k]+'.png')
