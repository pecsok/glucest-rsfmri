





import os
import glob
import numpy as np
import pandas as pd
import network_fcon as fc
import scipy as sp
from scipy.stats import pearsonr
from scipy.stats import linregress
import seaborn as sns
import matplotlib.pyplot as plt
import re





# Set paths
inpath = "/Users/pecsok/Desktop/ImageData/PMACS_remote/data/fmri/postprocessed/3T/xcp_d"
outpath = "~/Desktop/ImageData/PMACS_remote/analysis/postprocessing/"
clinpath = "~/Desktop/ImageData/PMACS_remote/data/clinical"
cestpath = "/Users/pecsok/Desktop/ImageData/PMACS_remote/data/cest/output_measures/UNI/"

# Choose what to analyse
networks = ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"] 
CESTnetworks = ["avgCEST_Cont", "ctCEST_Cont", "avgCEST_Default", "ctCEST_Default","avgCEST_SomMot", "ctCEST_SomMot", "avgCEST_DorsAttn", "ctCEST_DorsAttn", "avgCEST_Vis", "ctCEST_Vis","avgCEST_Limbic", "ctCEST_Limbic",  "avgCEST_SalVentAttn","ctCEST_SalVentAttn"]
CNB_scores = ["tap_tot", "er40_cr", "medf_pc"] #, 
CNB_valids = ["tap_valid", "er40_valid", "medf_valid"] #, 
diag_scores = ["dx_pscat"] # ,"axis1_desc1","axis1_stat1"
demo_scores = ["sex", "age", "race","ethnic","dateDiff"]
diag_details = ["axis1_desc1", "axis1_desc2", "axis1_desc3","axis1_desc4","axis1_desc5", "axis1_desc6"]

# Make dataframe based on metrics of interest
#columns = ["BBLID"] + ["Session"] + networks
#fcon_df = pd.DataFrame(columns=columns)
#clin_df = pd.DataFrame(columns=["BBLID", "Session"] + CNB_scores + clinical_scores + diag_scores)
grp_df = pd.DataFrame(columns = ["BBLID"] + ["Session"] + demo_scores + networks + CESTnetworks + CNB_scores + diag_scores)
diag_df = pd.DataFrame(columns = ["BBLID"] + ["Session"] + diag_scores + diag_details)
print(grp_df)

# Initialize empty lists and vars
bblids = []
sesids = []
both3T_7T = []

# Import group dataframes and set indices
subjlist = pd.read_csv("~/Desktop/ImageData/PMACS_remote/data/pipeline_input_all_subj.csv", sep=',') 
cnbmat = pd.read_csv(clinpath + "/maggie_datarequest_fullcnb-2.csv", sep=',') 
diagmat = pd.read_csv(clinpath + "/maggie_datarequest_fullcnb-2.csv", sep=',')
demomat = pd.read_csv(clinpath + "/maggie_datarequest_demographics-2.csv", sep=',')
# cestmat = pd.read_csv(clinpath + "/demographics.csv", sep='\t') add grp CEST map here

# Reformat some dfs
cnbmat.set_index('bblid', inplace = True)
diagmat.set_index('bblid', inplace = True)
demomat.set_index('bblid', inplace = True)
subjlist = subjlist.dropna(how='all')
subjlist.rename(columns={'fMRI Field Strength': 'fieldstrength'},inplace=True)
# FIXXXXX Correct subject list for future! 
subjlist.loc[subjlist['BBLID'] == 88608.0, 'SCANID_rs'] = 'motive2'
subjlist.loc[subjlist['BBLID'] == 20792.0, 'SCANID_rs'] = 'motive2'
subjlist.loc[subjlist['BBLID'] == 88760.0, 'SCANID_rs'] = 'motive2'
subjlist.loc[subjlist['BBLID'] == 112126.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 91962.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 89279.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 91422.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 121407.0, 'SCANID_rs'] = '9257'
print(subjlist)  
              
print("yes")
#### Troubleshooting: Initialize empty matrix for fcmats # FIX if desired:
#num_matrices = 100  # You can change this to the desired number
#matrix_shape = (700, 701)
#index = pd.MultiIndex.from_product([range(num_matrices), range(matrix_shape[0]), range(matrix_shape[1])], names=['Matrix', 'Row', 'Column'])
#fcmats = pd.DataFrame(data, index=index, columns=['Value'])

print(subjlist.loc[subjlist['BBLID'] == 20792.0, 'SCANID_rs'])





fieldstrength = '3T'
runfcon = True
runCNB = True
rundiag = True
rundemo = True
runcest = True
run_grpanalysis = True








# First, make df to keep track of who has 3T and 7T fMRI scan.
subjs = subjlist['BBLID']
for subj in subjs:
    bblid = str(int(subj))
    ses=subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_rs'].values
    if len(ses) >1: # & fieldstrength = '7T':
        both3T_7T.append(bblid)
both3T_7T = pd.DataFrame(both3T_7T)
both3T_7T.to_csv('both3T_7T.csv', index=True)

# Generates list of all file names
folder_names = [folder for folder in glob.glob(os.path.join(inpath, "*")) if os.path.isdir(folder)]
# Loop through subjects


# OLD CHUNK
for subj_path in folder_names:
    if "sub" in subj_path:
        # Extract bblid id:
        # print(subj_path)
        bblid = subj_path.split('-')[1]
        print("Processing subject " + bblid)
        # Extract session id: 
        items = os.listdir(subj_path)
        ses_folder = [item for item in items if item.startswith("ses")]
        ses = ses_folder[0].split('-')[1]
        ses_path = os.path.join(inpath, subj_path, ses_folder[0]) # full path to session
        # Add to running list of IDs grp analysis later:
        bblids.append(bblid)
        sesids.append(ses)
        # Start new row in grp_df for this subject:
        ids = [bblid, ses]  # Values for the first two columns
        grp_df.loc[len(grp_df)] = ids + [float('nan')] * (len(grp_df.columns) - len(ids))
        diag_df.loc[len(diag_df)] = ids + [float('nan')] * (len(diag_df.columns) - len(ids))

# OLD CHUNK 
subjlist = subjlist[subjlist['fieldstrength']=='3T']
subjs = subjlist['BBLID']
for subj in subjs:
    bblid = str(int(subj))
    ses=subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_rs'].values #CEST  fcmat.columns[fcmat.columns.str.contains(network)]]
#    ses=ses[0] # Change for 3T vs 7T!!!!
    ses_path = os.path.join(inpath, "sub-" + bblid, "ses-" + ses[0])
    ids = [bblid, ses]  # Values for the first two columns
    grp_df.loc[len(grp_df)] = ids + [float('nan')] * (len(grp_df.columns) - len(ids))
    diag_df.loc[len(diag_df)] = ids + [float('nan')] * (len(diag_df.columns) - len(ids))
 #   print(ids)
    # Run a subset of subjs or exclude specific subjs.
    if bblid != "102041" and bblid != "20082": #bblid != "20902" and bblid != "93242"  and bblid != "20754" and bblid != "127065" and 
        ##################################################################################################
        ## FC
        ##################################################################################################
        if runfcon:
        #    print("yes")
            fcmat_glob = f"{ses_path}/func/*Schaefer117_measure-pearsoncorrelation_conmat.tsv"
        #    print(fcmat_glob)
            if glob.glob(fcmat_glob) and os.path.isfile(glob.glob(fcmat_glob)[0]): # FIX this is giving error when file doesn't e
                fcmat = pd.read_csv(glob.glob(fcmat_glob)[0], sep='\t') 
                fcmat.set_index('Node', inplace = True)
                # Loop through the networks
                print("Running fcon")
                for network in networks:
                    # Select rows and columns corresponding to the network
                    network_fc = fcmat.loc[fcmat.index.str.contains(network), fcmat.columns[fcmat.columns.str.contains(network)]]
                    #print(network_fc)
                    # Calculate avg network fc and add value to proper column in grp_df
                    grp_df.loc[len(grp_df)-1, network] = network_fc.values.mean()










# loop through subjs and create grp_df
# .values[0].astype(str) 
subjlist = subjlist[subjlist['fieldstrength']== fieldstrength]
subjs = subjlist['BBLID']
for subj in subjs:
    bblid = str(int(subj))
    ses=subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_rs'].values  #FIX array --> string format  fcmat.columns[fcmat.columns.str.contains(network)]]
    ses_path = os.path.join(inpath, "sub-" + bblid, "ses-" + ses[0])
    ids = [bblid, ses]  # Values for the first two columns
    grp_df.loc[len(grp_df)] = ids + [float('nan')] * (len(grp_df.columns) - len(ids))
    diag_df.loc[len(diag_df)] = ids + [float('nan')] * (len(diag_df.columns) - len(ids))
    
    # Run a subset of subjs or exclude specific subjs.
    if bblid != "102041" and bblid != "20082" and bblid != "88760" and bblid != "20916" and bblid != "22473" and bblid != "132869": 
        ##################################################################################################
        ## CEST
        ##################################################################################################
        if runcest: #88760's CEST output is empty for some reason.
            print("Processing " + bblid + "'s CEST data'")
            # Extract Glu session ID
            gluses = subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_CEST'].values[0].astype(str) #.
            cestid = bblid + "_" + gluses
            # Import data
            for network in networks:
                cest_pattern = cestpath + cestid + "/" + cestid + "-2d-GluCEST-s100_7-" + network + "-measures_UNI.tsv"
                cestfile = glob.glob(cest_pattern)
                for file in cestfile:
                    if cestfile and os.path.isfile(file):
                        cestmat = pd.read_csv(file, sep='\t') 
                        means = [] 
                        counts = []
                        col_name = "avgCEST_" + network # for grp_df
                        ct_name = "ctCEST_" + network # for grp_df
                        for index, value in enumerate(cestmat.loc[0,:]):
                             if "Mean" in cestmat.columns[index] and not np.isnan(value):
                                # cestmat.at[0, cestmat.columns[index]] = float(value) * float(cestmat.iloc[0, index + 1])
                                means.append(cestmat.at[0, cestmat.columns[index]])
                                counts.append(cestmat.at[0, cestmat.columns[index + 1]])
                        if sum(counts) == 0:
                            grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == col_name] = "NaN"
                            grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == col_name] = "NaN"
                        else:
                            grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == col_name] = sum(means) # / sum(counts)
                            grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == ct_name] = sum(counts) # / sum(counts)

        ##################################################################################################
        ## FC
        ##################################################################################################
        if runfcon:
            fcmat_glob = f"{ses_path}/func/*Schaefer117_measure-pearsoncorrelation_conmat.tsv"
            if glob.glob(fcmat_glob) and os.path.isfile(glob.glob(fcmat_glob)[0]): # FIX this is giving error when file doesn't e
                fcmat = pd.read_csv(glob.glob(fcmat_glob)[0], sep='\t') 
                fcmat.set_index('Node', inplace = True)
                # Loop through the networks
                print("Running fcon")
                for network in networks:
                    # Select rows and columns corresponding to the network
                    network_fc = fcmat.loc[fcmat.index.str.contains(network), fcmat.columns[fcmat.columns.str.contains(network)]]
                    #print(network_fc)
                    # Calculate avg network fc and add value to proper column in grp_df
                    grp_df.loc[len(grp_df)-1, network] = network_fc.values.mean()
            ##################################################################################################
            ## CNB
            ##################################################################################################
            if runCNB:
                # Loop through the CNB scores
                for i in range(len(CNB_scores)):
                    CNB_score = CNB_scores[i]
                    CNB_valid = CNB_valids[i]
                    # Select score of interest & validity of that score
                    scores = cnbmat[CNB_score]
                    if int(bblid) in scores.index:
                        score = scores[int(bblid)]
                        valids = cnbmat[CNB_valid]
                        valid = str(valids[int(bblid)])
                        # If score was valid, add to grp_df
                        if 'V' in valid:
                            grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == CNB_score] = score 
            ##################################################################################################
            ## Diagnosis
            ##################################################################################################
            if rundiag:
                # Loop through the CNB scores
                for i in range(len(diag_scores)):
                    diag_score = diag_scores[i]
                    # Select score of interest and add to grp_df
                    diagnoses = diagmat[diag_score]
                    if int(bblid) in diagnoses.index:
                        diagnosis = diagnoses[int(bblid)]
                        grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == diag_score] = diagnosis 
                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_score] = diagnosis 
                    else:
                        diagnosis = "Unknown"
                        grp_df.loc[grp_df['BBLID'].astype(str) == bblid, grp_df.columns == diag_score] = diagnosis 
                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_score] = diagnosis
                
                # Loop through diag scores
                for i in range(len(diag_details)):
                    diag_detail = diag_details[i]
                    # Select score of interest and add to grp_df
                    comorbidities = diagmat[diag_detail]
                    if int(bblid) in comorbidities.index:
                        comorbidity = comorbidities[int(bblid)]
                       # print(comorbidity)
                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_detail] = comorbidity 
                    else:
                        comorbidity = "Unknown"
                        diag_df.loc[diag_df['BBLID'].astype(str) == bblid, diag_df.columns == diag_detail] = comorbidity
                        
            ##################################################################################################
            ## Demographics
            ##################################################################################################
            if rundemo:
                # Loop through the CNB scores
                for i in range(len(demo_scores)):
                    demo_score = demo_scores[i]
                    # Select metric of interest
                    scores = demomat[demo_score]
                    if int(bblid) in scores.index:
                        score = scores[int(bblid)]
                        # Add to grp_df
                        grp_df.loc[grp_df['BBLID'] == bblid, grp_df.columns == demo_score] = score 

print(grp_df)








grp_df.to_csv('grp_df_3T.csv', index=True)
diag_df.to_csv('diag_df_3T.csv', index=True)














    


!jupyter nbconvert --to html pipeline.ipynb --output pipeline_3T.html





if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
        
    # Create a scatter plot with a linear regression line
    for network in networks:
        print(grp_df)
        cestcol = "avgCEST_" + network
        #graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
        graph_df = grp_df
        graph_df = graph_df.dropna(subset=[network, cestcol, 'dx_pscat'])
        # Create a linear regression model for fcon
        color = colors.loc[colors['Network'] == network, 'Color'].values[0]
        sns.set_palette(color)
        plot = sns.lmplot(x=network, y=cestcol, data=graph_df, markers= "x") #hue='dx_pscat', 
        if network == "SalVentAttn":
            plt.xlabel("SN", fontsize=16)
            plt.ylabel("avgCEST_SN", fontsize=16)
            plt.title('SN FC versus SN GluCEST', fontsize = 20)
        else:
            plt.xlabel(network, fontsize=16)
            plt.ylabel(cestcol, fontsize=16)
            plt.title(network + ' FC versus ' + network + ' GluCEST' , fontsize = 20)
        # Generate and add slope, r2 and p for subset 1
 #       slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', network], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
 #       plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
   #     # Generate and add slope, r2 and p for subset 2
 #       slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'HC', network], graph_df.loc[graph_df['dx_pscat'] == 'HC', cestcol])
 #       plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
        # Generate and add slope, r2 and p for all data
        slope, intercept, r_value, p_value, std_err = linregress(graph_df[network], graph_df[cestcol])
        plt.text(0.1, 0.8, f'All\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
        plt.show() 

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, 'dx_pscat'])
            # Add labels and a title to the plot
            plot = sns.lmplot(x=cestcol, y=CNB_score,data=graph_df) # hue='dx_pscat',
            if network == "SalVentAttn":
                plt.xlabel("avgCEST_SN", fontsize=16)
                plt.title('SN GluCEST versus ' + CNB_score, fontsize = 20)
            else: 
                plt.xlabel(cestcol, fontsize=16)
                plt.title(network + ' GluCEST versus ' + CNB_score, fontsize = 20)
            plt.ylabel(CNB_score, fontsize=16)
            # Generate and add slope, r2 and p for subset 1
   #         slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
   #         plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for subset 2
    #        slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'HC', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'HC', cestcol])
    #        plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for all data
            slope, intercept, r_value, p_value, std_err = linregress(graph_df[CNB_score], graph_df[cestcol])
            plt.text(0.1, 0.8, f'All\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)   
            # Show the plot
            plt.show()    
            
            #graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, network, 'dx_pscat'])
            # Add labels and a title to the plot
            plot = sns.lmplot(x=network, y=CNB_score, data=graph_df, markers= "s") #hue='dx_pscat',
            if network == "SalVentAttn":
                plt.xlabel("SN", fontsize=16)
                plt.title('SN FC versus ' + CNB_score, fontsize = 20)
            else:
                plt.xlabel(network, fontsize=16)
                plt.title(network + ' FC versus ' + CNB_score, fontsize = 20)
            plt.ylabel(CNB_score, fontsize=16)
            # Generate and add slope, r2 and p for subset 1
  #          slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'PSY', network])
  #          plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for subset 2
   #         slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'HC', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'HC', network])
   #         plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for all data
            slope, intercept, r_value, p_value, std_err = linregress(graph_df[CNB_score], graph_df[network])
            plt.text(0.1, 0.8, f'All\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)   
            # Show the plot
            plt.show()  
       
        # Make bar graph comparing diagnostic groups
        avg_df = grp_df.groupby('dx_pscat').agg({cestcol: ['mean', 'std'], network: ['mean', 'std']}).reset_index()
        # Flatten the multi-level columns
        avg_df.columns = ['_'.join(col).strip() for col in avg_df.columns.values]
        print(avg_df)

        # Plot CEST bar graph with error bars
        sns.barplot(x='dx_pscat_', y=cestcol + '_mean', data=avg_df, yerr=avg_df[cestcol + '_std'], label='CEST')
        plt.xlabel('Diagnostic Group')
        plt.ylabel('Mean Value')
        plt.ylim(5, 9.5)
        plt.title('Average CEST for each dx_pscat group')
        plt.legend()
        plt.show()

        # Plot fcon bar graph with error bars
        sns.barplot(x='dx_pscat_', y=network + '_mean', data=avg_df, yerr=avg_df[network + '_std'], label='fcon')
        plt.xlabel('Diagnostic Group')
        plt.ylabel('Mean Value')
        plt.title('Average fcon for each dx_pscat group')
        plt.legend()
        plt.show()
        
        # Make bar graph comparing network-level CEST and fcon levels
        #





#CLUNKIER COMPREHENSIVE VERSION:

from sklearn import linear_model
import statsmodels.api as sm
import statsmodels.formula.api as smf

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
    
    anova_tables = []
    # Create a scatter plot with a multiple linear regression 
    for network in networks:
        cestcol = "avgCEST_" + network
        # Create a linear regression model for fcon
       # color = colors.loc[colors['Network'] == network, 'Color'].values[0]
       # sns.set_palette(color)

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]
            # Define x values and target variable
            X = graph_df[[cestcol, network]]
            Y = graph_df[CNB_score]

            ##################################
            # Define formula and model
            formula = f'{CNB_score} ~ {cestcol} + {network}'
            model = smf.ols(formula=formula, data=graph_df).fit()
            print('\n\n\n' + network + ' & ' + CNB_score) 
            print(model.summary())

            # Plotting the regression line
            fig, ax = plt.subplots()
            ax.scatter(graph_df[cestcol], graph_df[CNB_score], label='Actual Data')
            # Generate x values for the line
            x_line = pd.DataFrame({cestcol: np.linspace(graph_df[cestcol].min(), graph_df[cestcol].max(), 100),
                                   network: np.mean(graph_df[network])})  # Use mean value for the network variable
            # Predictions for the regression line
            y_line = model.predict(x_line)
            # Plot the regression line
            ax.plot(x_line[cestcol], y_line, color='red', label='Regression Line')
            ax.set_xlabel(cestcol)
            ax.set_ylabel(CNB_score)
            ax.set_title('Multiple Linear Regression Plot for ' + CNB_score + ' & ' + network)
            ax.legend()
            plt.show()



#CLUNKIER COMPREHENSIVE VERSION:

from sklearn import linear_model
import statsmodels.api as sm
import statsmodels.formula.api as smf

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
    
    anova_tables = []
    # Create a scatter plot with a multiple linear regression 
    for network in networks:
        cestcol = "avgCEST_" + network
        # Create a linear regression model for fcon
       # color = colors.loc[colors['Network'] == network, 'Color'].values[0]
       # sns.set_palette(color)

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]
            # Define x values and target variable
            X = graph_df[[cestcol, network]]
            Y = graph_df[CNB_score]
            
            ##################################
            # Define formula and model
            formula = f'{CNB_score} ~ {cestcol} + {network}'
            model = smf.ols(formula=formula, data=graph_df).fit()
            print(network + CNB_score)
            print(model.summary())
            
            



######## OLD CODE

from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
import statsmodels.formula.api as smf

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)

    anova_tables = []
    for network in networks:
        cestcol = "avgCEST_" + network
        
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]

            ##################################
            # Define Linear Regression formula and model
            formula = f'{CNB_score} ~ {cestcol} + {network}'
            model = smf.ols(formula=formula, data=graph_df).fit()

            print('Intercept:', model.params[0])
            print('Coefficients:', model.params[1:])

            # Perform ANOVA and print results
            anova_table = sm.stats.anova_lm(model, typ=2)
            anova_tables.append(anova_table)
            print(network + "-" + CNB_score + " ANOVA Results:")
            print(anova_table)
            
            
            
            
            
            
            
            
            
            
            
            
              # Adjust diagnostic Labels
        value_counts = grp_df['dx_pscat'].value_counts()
        print(value_counts)
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NaN', 'Other')
        
        value_counts = grp_df['dx_pscat'].value_counts()
        print(value_counts)
        print(grp_df)
        # Make bar graph comparing diagnostic groups
        avg_df = graph_df.groupby('dx_pscat').agg({cestcol: ['mean', 'std'], network: ['mean', 'std']}).reset_index()
        # Flatten the multi-level columns
        avg_df.columns = ['_'.join(col).strip() for col in avg_df.columns.values]
        print(avg_df)
 
        colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'Blues_d', 'terrain_r']}) # 

    
for network in networks:
    cestcol = "avgCEST_" + network
  #  graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
    graph_df = graph_df.dropna(subset=[network, cestcol, 'dx_pscat'])
    # Create a linear regression model for fcon
    color = colors.loc[palette['Network'] == network, 'Color'].values[0]
    sns.set_palette(color)
    plot = sns.lmplot(x=network, y=cestcol,  data=graph_df) #hue='dx_pscat',
    if network == "SalVentAttn":
        print("yes")
        plt.xlabel("SN")
    else:
        plt.xlabel(network)
    plt.ylabel(cestcol)
    # Generate and add slope, r2 and p for subset 1
    slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', network], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
    plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    # Generate and add slope, r2 and p for subset 2
    slope, intercept, r_value, p_value, std_err = linregress(graph_df[network], graph_df[cestcol])
    plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    
    plt.title('Linear Regression between ' + network + ' fcon and ' + network + ' cest')
    plt.show() 
        


#BBS2

from sklearn import linear_model
import statsmodels.api as sm
import statsmodels.formula.api as smf
import numpy as np
import matplotlib.pyplot as plt

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
    
    anova_tables = []
    # Create a scatter plot with a multiple linear regression 
    for network in networks:
        cestcol = "avgCEST_" + network
        # Create a linear regression model for fcon
       # color = colors.loc[colors['Network'] == network, 'Color'].values[0]
       # sns.set_palette(color)

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]
            # Define x values and target variable
            X = graph_df[[cestcol, network]]
            Y = graph_df[CNB_score]
            
            ##################################
            # Define formula and model
            #formula = f'{CNB_score} ~ {cestcol} + {network}'
            #model = smf.ols(formula=formula, data=graph_df).fit()
            #print(network + CNB_score)
            #print(model.summary())
            print(graph_df)
            fig = plt.figure()
            ax = fig.add_subplot(111, projection = '3d')
            ax.scatter(graph_df[CNB_score], graph_df[cestcol], graph_df[network])
            ax.set_xlabel(CNB_score)
            ax.set_ylabel(cestcol)
            ax.set_zlabel(network)
            plt.show()
            
            

