





import os
import glob
import numpy as np
import pandas as pd
import network_fcon as fc
import scipy as sp
from scipy.stats import pearsonr
from scipy.stats import linregress
import seaborn as sns
import matplotlib.pyplot as plt
import re





# Set paths
inpath = "/Users/pecsok/Desktop/ImageData/PMACS_remote/data/fmri/postprocessed/3T/xcp_d"
outpath = "~/Desktop/ImageData/PMACS_remote/analysis/postprocessing/"
clinpath = "~/Desktop/ImageData/PMACS_remote/data/clinical"
cestpath = "/Users/pecsok/Desktop/ImageData/PMACS_remote/data/cest/output_measures/UNI/"

# Choose what to analyse
networks = ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"] 
CESTnetworks = ["avgCEST_Cont", "ctCEST_Cont", "avgCEST_Default", "ctCEST_Default","avgCEST_SomMot", "ctCEST_SomMot", "avgCEST_DorsAttn", "ctCEST_DorsAttn", "avgCEST_Vis", "ctCEST_Vis","avgCEST_Limbic", "ctCEST_Limbic",  "avgCEST_SalVentAttn","ctCEST_SalVentAttn"]
diag_scores = ["dx_pscat", "hstatus","sex", "age", "race","ethnic"] # ,"axis1_desc1","axis1_stat1"
diag_details = ["axis1_desc1", "axis1_desc2", "axis1_desc3","axis1_desc4","axis1_desc5", "axis1_desc6"]

# Make output dataframes based on metrics of interest
grp_df = pd.DataFrame(columns = ["BBLID"] + ["Session"] +  networks + CESTnetworks +  diag_scores)
diag_df = pd.DataFrame(columns = ["BBLID"] + ["Session"] + diag_scores + diag_details)
print(grp_df)

# Create parcellated output dfs
fc_parcelmat = pd.DataFrame(columns = ["BBLID","Session"] + diag_scores + [str(i) for i in range(51, 101)])
reho_parcelmat = pd.DataFrame(columns = ["BBLID"] + ["Session"] + diag_scores + [str(i) for i in range(51, 101)])
print(fc_parcelmat)
cestcolumns = []
for i in range(51, 101):
    cestcolumns.append(f'NZMean_{i}')
    cestcolumns.append(f'NZcount_{i}')
cest_parcelmat = pd.DataFrame(columns = ["BBLID"] + ["Session"] + diag_scores + cestcolumns)


# Initialize empty lists and vars
bblids = []
sesids = []
both3T_7T = []

# Import group dataframes and set indices
subjlist = pd.read_csv("~/Desktop/ImageData/PMACS_remote/data/pipeline_input_all_subj.csv", sep=',') 
cnbmat = pd.read_csv(clinpath + "/maggie_datarequest_fullcnb-2.csv", sep=',') 
diagmat = pd.read_csv(clinpath + "/maggie_datarequest_diagnosis-2.csv", sep=',')
demomat = pd.read_csv(clinpath + "/maggie_datarequest_demographics-2.csv", sep=',')
# cestmat = pd.read_csv(clinpath + "/demographics.csv", sep='\t') add grp CEST map here

# Reformat some dfs
cnbmat.set_index('bblid', inplace = True)
diagmat.set_index('bblid', inplace = True)
demomat.set_index('bblid', inplace = True)
subjlist = subjlist.dropna(how='all')
subjlist.rename(columns={'fMRI Field Strength': 'fieldstrength'},inplace=True)
# FIXXXXX Correct subject list for future! 
subjlist.loc[subjlist['BBLID'] == 88608.0, 'SCANID_rs'] = 'motive2'
subjlist.loc[subjlist['BBLID'] == 20792.0, 'SCANID_rs'] = 'motive2'
subjlist.loc[subjlist['BBLID'] == 88760.0, 'SCANID_rs'] = 'motive2'
subjlist.loc[subjlist['BBLID'] == 112126.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 91962.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 89279.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 91422.0, 'SCANID_rs'] = 'motive1'
subjlist.loc[subjlist['BBLID'] == 121407.0, 'SCANID_rs'] = '9257'
print(subjlist)  
              
print("yes")
#### Troubleshooting: Initialize empty matrix for fcmats # FIX if desired:
#num_matrices = 100  # You can change this to the desired number
#matrix_shape = (700, 701)
#index = pd.MultiIndex.from_product([range(num_matrices), range(matrix_shape[0]), range(matrix_shape[1])], names=['Matrix', 'Row', 'Column'])
#fcmats = pd.DataFrame(data, index=index, columns=['Value'])

print(subjlist.loc[subjlist['BBLID'] == 20792.0, 'SCANID_rs'])





fieldstrength = '3T'
runfcon = False
runreho = True
runCNB = False
rundiag = False
rundemo = False
runcest = False
run_grpanalysis = False





print(reho_parcelmat)



# First, subset subjlist to only include participants with fieldstrength of interest. 
subjlist = subjlist[subjlist['fieldstrength'] == '3T']
# Select BBLID column and loop through all subjs.
subjs = subjlist['BBLID']

for subj in subjs:
    # Set variables and paths:
    bblid = str(int(subj))
    ses=subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_rs'].values
    ses_path = os.path.join(inpath, "sub-" + bblid, "ses-" + ses[0])
    ids = [bblid, ses]  # Values for the first two columns
    grp_df.loc[len(grp_df)] = ids + [float('nan')] * (len(grp_df.columns) - len(ids))
    diag_df.loc[len(diag_df)] = ids + [float('nan')] * (len(diag_df.columns) - len(ids))
    fc_parcelmat.loc[len(fc_parcelmat)] = ids + [float('nan')] * (len(fc_parcelmat.columns) - len(ids))
    cest_parcelmat.loc[len(cest_parcelmat)] = ids + [float('nan')] * (len(cest_parcelmat.columns) - len(ids))
    reho_parcelmat.loc[len(reho_parcelmat)] = ids + [float('nan')] * (len(reho_parcelmat.columns) - len(ids))
    #fc_parcelmat.set_index('BBLID', inplace = True)
    #cest_parcelmat.set_index('BBLID', inplace = True)
    
    if bblid != "102041" and bblid != "20082" and bblid != "88760" and bblid != "20916" and bblid != "22473" and bblid != "132869": 
        ##################################################################################################
        ## CEST
        ##################################################################################################
        if runcest: #88760's CEST output is empty for some reason.
            print("Processing " + bblid + "'s CEST data'")
            # Extract Glu session ID
            gluses = subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_CEST'].values[0].astype(str) #.
            cestid = bblid + "_" + gluses
            # Import data
            cest_pattern = cestpath + cestid + "/" + cestid + "-Schaefer2018ROI-GluCEST-100P-17N-measures_UNI.tsv"
            #print(cest_pattern)
            cestfile = glob.glob(cest_pattern)
            #print(cestfile)
            for file in cestfile:
                if cestfile and os.path.isfile(file):
                    cestmat = pd.read_csv(file, sep='\t')
                    for i in range(51, 101):
                        col_name = f'NZMean_{i}'
                        ct_name = f'NZcount_{i}'
                        if col_name in cestmat.columns:
                            mean = cestmat[col_name].values
                            count = cestmat[ct_name].values
                            cest_parcelmat.loc[cest_parcelmat['BBLID'] == bblid, cest_parcelmat.columns == col_name] = mean[0]
                            cest_parcelmat.loc[cest_parcelmat['BBLID'] == bblid, cest_parcelmat.columns == ct_name] = count[0]

    ##################################################################################################
    ## FC
    ##################################################################################################
    if runfcon:
        fcmat_glob = f"{ses_path}/func/*Schaefer117_measure-pearsoncorrelation_conmat.tsv"
        if glob.glob(fcmat_glob) and os.path.isfile(glob.glob(fcmat_glob)[0]): # FIX this is giving error when file doesn't e
            fcmat = pd.read_csv(glob.glob(fcmat_glob)[0], sep='\t') 
            fcmat.set_index('Node', inplace = True)
            #print(fcmat)
        
            # Loop through the networks
            print("Running fcon")

            # Select rows and columns corresponding to the network
            np.fill_diagonal(fcmat.values, np.nan)
            fcmat['avg_fc'] = fcmat.mean(axis=1, skipna=True)
            fc_last50 = fcmat['avg_fc'].tail(50).values
            last50 = pd.DataFrame(fc_last50).T
            last50 = last50.rename(columns={i: str(i+1) for i in range(50)})
            fc_parcelmat.iloc[fc_parcelmat['BBLID'] == bblid, 8:] = fc_last50 #fc_parcelmat.index == bblid

    ##################################################################################################
    ## RH
    ##################################################################################################
    if runreho:
        rehomat_glob = f"{ses_path}/func/*Schaefer117_desc-reho_timeseries.tsv"
        if glob.glob(rehomat_glob) and os.path.isfile(glob.glob(rehomat_glob)[0]): # FIX this is giving error when file doesn't e
            rehomat = pd.read_csv(glob.glob(rehomat_glob)[0], sep='\t') 
            print(bblid)
            print(rehomat)
            # Loop through the networks
            print("Running reho")
            # Select rows and columns corresponding to the network
            last50 = rehomat.iloc[:,-50:] #.tail(50).values
            print(last50)
            print(len(last50))
            #last50 = pd.DataFrame(fc_last50).T
            #last50 = last50.rename(columns={i: str(i+1) for i in range(50)})
            reho_parcelmat.iloc[reho_parcelmat['BBLID'] == bblid, 8:] = last50 #fc_parcelmat.index == bblid


    ##################################################################################################
    ## Diagnosis
    ##################################################################################################
    if rundiag:
        # Add hstatus
        for i in range(len(diag_scores)):
            diag_score = diag_scores[i]
            # Select score of interest and add to grp_df
            diagnoses = diagmat[diag_score]
            if int(bblid) in diagnoses.index:
                diagnosis = diagnoses[int(bblid)]
                fc_parcelmat.iloc[fc_parcelmat['BBLID'] == bblid, fc_parcelmat.columns == diag_score ] = diagnosis
                cest_parcelmat.iloc[cest_parcelmat['BBLID'] == bblid, cest_parcelmat.columns == diag_score ] = diagnosis
            else:
                diagnosis = "Unknown"
                fc_parcelmat.iloc[fc_parcelmat['BBLID'] == bblid, fc_parcelmat.columns == diag_score ] = diagnosis
                cest_parcelmat.iloc[cest_parcelmat['BBLID'] == bblid, cest_parcelmat.columns == diag_score ] = diagnosis

print("done")


print(cest_parcelmat)
reho_parcelmat.to_csv('reho_parcelmat.csv', index=True)


# Loop through other cest output folders  FIX THIS FIGURE OUT PATHS
cestfolders = ["/Users/pecsok/Desktop/ImageData/PMACS_remote/data/cest/analysis_batch2/output_measures/UNI/", 
               "/Users/pecsok/Desktop/ImageData/PMACS_remote/data/cest/analysis_batch3/output_measures/UNI/",
               "/Users/pecsok/Desktop/ImageData/PMACS_remote/data/cest/March_addons/"]

"""
for subj in subjs:
    # Set variables and paths:
    bblid = str(int(subj))
    ses=subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_rs'].values
    ses_path = os.path.join(inpath, "sub-" + bblid, "ses-" + ses[0])
    ids = [bblid, ses]  # Values for the first two columns
    grp_df.loc[len(grp_df)] = ids + [float('nan')] * (len(grp_df.columns) - len(ids))
    diag_df.loc[len(diag_df)] = ids + [float('nan')] * (len(diag_df.columns) - len(ids))
    fc_parcelmat.loc[len(fc_parcelmat)] = ids + [float('nan')] * (len(fc_parcelmat.columns) - len(ids))
    cest_parcelmat.loc[len(cest_parcelmat)] = ids + [float('nan')] * (len(cest_parcelmat.columns) - len(ids))
    #fc_parcelmat.set_index('BBLID', inplace = True)
    #cest_parcelmat.set_index('BBLID', inplace = True)
    
    if bblid != "102041" and bblid != "20082" and bblid != "88760" and bblid != "20916" and bblid != "22473" and bblid != "132869": 
        # If statement to only run cest code on people who haven't been added yet:
        bblid_parcelmat = cest_parcelmat[cest_parcelmat['BBLID'] == bblid]
        if np.isnan(bblid_parcelmat.iloc[0, bblid_parcelmat.columns.get_loc("NZMean_52")]):
            ##################################################################################################
            ## CEST
            ##################################################################################################
            for cestfolder in cestfolders:
                if runcest: #88760's CEST output is empty for some reason.
                    print("Processing " + bblid + "'s CEST data'")
                    # Extract Glu session ID
                    gluses = subjlist.loc[subjlist['BBLID'] == float(bblid), 'SCANID_CEST'].values[0].astype(str) #.
                    cestid = bblid + "_" + gluses
                    # Import data
                    cest_pattern = cestfolder + cestid + "/" + cestid + "-Schaefer2018ROI-GluCEST-100P-17N-measures_UNI.tsv"
                    print(cest_pattern)
                    cestfile = glob.glob(cest_pattern)
                    for file in cestfile:
                        if cestfile and os.path.isfile(file):
                            cestmat = pd.read_csv(file, sep='\t')
                            print(cestmat)
                            for i in range(51, 101):
                                col_name = f'NZMean_{i}'
                                ct_name = f'NZcount_{i}'
                                if col_name in cestmat.columns:
                                    mean = cestmat[col_name].values
                                    count = cestmat[ct_name].values
                                    print(mean)
                                    print(count)
                                    cest_parcelmat.loc[cest_parcelmat['BBLID'] == bblid, cest_parcelmat.columns == col_name] = mean[0]
                                    cest_parcelmat.loc[cest_parcelmat['BBLID'] == bblid, cest_parcelmat.columns == ct_name] = count[0]
        else: 
            print(bblid)
            print("Already in there")
"""      


cest_parcelmat.to_csv('cest_parcelmat_3T.csv', index=True)
fc_parcelmat.to_csv('fc_parcelmat_3T.csv', index=True)




















    


!jupyter nbconvert --to html pipeline.ipynb --output pipeline_3T.html





if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
        
    # Create a scatter plot with a linear regression line
    for network in networks:
        print(grp_df)
        cestcol = "avgCEST_" + network
        #graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
        graph_df = grp_df
        graph_df = graph_df.dropna(subset=[network, cestcol, 'dx_pscat'])
        # Create a linear regression model for fcon
        color = colors.loc[colors['Network'] == network, 'Color'].values[0]
        sns.set_palette(color)
        plot = sns.lmplot(x=network, y=cestcol, data=graph_df, markers= "x") #hue='dx_pscat', 
        if network == "SalVentAttn":
            plt.xlabel("SN", fontsize=16)
            plt.ylabel("avgCEST_SN", fontsize=16)
            plt.title('SN FC versus SN GluCEST', fontsize = 20)
        else:
            plt.xlabel(network, fontsize=16)
            plt.ylabel(cestcol, fontsize=16)
            plt.title(network + ' FC versus ' + network + ' GluCEST' , fontsize = 20)
        # Generate and add slope, r2 and p for subset 1
 #       slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', network], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
 #       plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
   #     # Generate and add slope, r2 and p for subset 2
 #       slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'HC', network], graph_df.loc[graph_df['dx_pscat'] == 'HC', cestcol])
 #       plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
        # Generate and add slope, r2 and p for all data
        slope, intercept, r_value, p_value, std_err = linregress(graph_df[network], graph_df[cestcol])
        plt.text(0.1, 0.8, f'All\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
        plt.show() 

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, 'dx_pscat'])
            # Add labels and a title to the plot
            plot = sns.lmplot(x=cestcol, y=CNB_score,data=graph_df) # hue='dx_pscat',
            if network == "SalVentAttn":
                plt.xlabel("avgCEST_SN", fontsize=16)
                plt.title('SN GluCEST versus ' + CNB_score, fontsize = 20)
            else: 
                plt.xlabel(cestcol, fontsize=16)
                plt.title(network + ' GluCEST versus ' + CNB_score, fontsize = 20)
            plt.ylabel(CNB_score, fontsize=16)
            # Generate and add slope, r2 and p for subset 1
   #         slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
   #         plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for subset 2
    #        slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'HC', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'HC', cestcol])
    #        plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for all data
            slope, intercept, r_value, p_value, std_err = linregress(graph_df[CNB_score], graph_df[cestcol])
            plt.text(0.1, 0.8, f'All\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)   
            # Show the plot
            plt.show()    
            
            #graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, network, 'dx_pscat'])
            # Add labels and a title to the plot
            plot = sns.lmplot(x=network, y=CNB_score, data=graph_df, markers= "s") #hue='dx_pscat',
            if network == "SalVentAttn":
                plt.xlabel("SN", fontsize=16)
                plt.title('SN FC versus ' + CNB_score, fontsize = 20)
            else:
                plt.xlabel(network, fontsize=16)
                plt.title(network + ' FC versus ' + CNB_score, fontsize = 20)
            plt.ylabel(CNB_score, fontsize=16)
            # Generate and add slope, r2 and p for subset 1
  #          slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'PSY', network])
  #          plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for subset 2
   #         slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'HC', CNB_score], graph_df.loc[graph_df['dx_pscat'] == 'HC', network])
   #         plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
            # Generate and add slope, r2 and p for all data
            slope, intercept, r_value, p_value, std_err = linregress(graph_df[CNB_score], graph_df[network])
            plt.text(0.1, 0.8, f'All\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)   
            # Show the plot
            plt.show()  
       
        # Make bar graph comparing diagnostic groups
        avg_df = grp_df.groupby('dx_pscat').agg({cestcol: ['mean', 'std'], network: ['mean', 'std']}).reset_index()
        # Flatten the multi-level columns
        avg_df.columns = ['_'.join(col).strip() for col in avg_df.columns.values]
        print(avg_df)

        # Plot CEST bar graph with error bars
        sns.barplot(x='dx_pscat_', y=cestcol + '_mean', data=avg_df, yerr=avg_df[cestcol + '_std'], label='CEST')
        plt.xlabel('Diagnostic Group')
        plt.ylabel('Mean Value')
        plt.ylim(5, 9.5)
        plt.title('Average CEST for each dx_pscat group')
        plt.legend()
        plt.show()

        # Plot fcon bar graph with error bars
        sns.barplot(x='dx_pscat_', y=network + '_mean', data=avg_df, yerr=avg_df[network + '_std'], label='fcon')
        plt.xlabel('Diagnostic Group')
        plt.ylabel('Mean Value')
        plt.title('Average fcon for each dx_pscat group')
        plt.legend()
        plt.show()
        
        # Make bar graph comparing network-level CEST and fcon levels
        #





#CLUNKIER COMPREHENSIVE VERSION:

from sklearn import linear_model
import statsmodels.api as sm
import statsmodels.formula.api as smf

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
    
    anova_tables = []
    # Create a scatter plot with a multiple linear regression 
    for network in networks:
        cestcol = "avgCEST_" + network
        # Create a linear regression model for fcon
       # color = colors.loc[colors['Network'] == network, 'Color'].values[0]
       # sns.set_palette(color)

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]
            # Define x values and target variable
            X = graph_df[[cestcol, network]]
            Y = graph_df[CNB_score]

            ##################################
            # Define formula and model
            formula = f'{CNB_score} ~ {cestcol} + {network}'
            model = smf.ols(formula=formula, data=graph_df).fit()
            print('\n\n\n' + network + ' & ' + CNB_score) 
            print(model.summary())

            # Plotting the regression line
            fig, ax = plt.subplots()
            ax.scatter(graph_df[cestcol], graph_df[CNB_score], label='Actual Data')
            # Generate x values for the line
            x_line = pd.DataFrame({cestcol: np.linspace(graph_df[cestcol].min(), graph_df[cestcol].max(), 100),
                                   network: np.mean(graph_df[network])})  # Use mean value for the network variable
            # Predictions for the regression line
            y_line = model.predict(x_line)
            # Plot the regression line
            ax.plot(x_line[cestcol], y_line, color='red', label='Regression Line')
            ax.set_xlabel(cestcol)
            ax.set_ylabel(CNB_score)
            ax.set_title('Multiple Linear Regression Plot for ' + CNB_score + ' & ' + network)
            ax.legend()
            plt.show()



#CLUNKIER COMPREHENSIVE VERSION:

from sklearn import linear_model
import statsmodels.api as sm
import statsmodels.formula.api as smf

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
    
    anova_tables = []
    # Create a scatter plot with a multiple linear regression 
    for network in networks:
        cestcol = "avgCEST_" + network
        # Create a linear regression model for fcon
       # color = colors.loc[colors['Network'] == network, 'Color'].values[0]
       # sns.set_palette(color)

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]
            # Define x values and target variable
            X = graph_df[[cestcol, network]]
            Y = graph_df[CNB_score]
            
            ##################################
            # Define formula and model
            formula = f'{CNB_score} ~ {cestcol} + {network}'
            model = smf.ols(formula=formula, data=graph_df).fit()
            print(network + CNB_score)
            print(model.summary())
            
            



######## OLD CODE

from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
import statsmodels.formula.api as smf

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)

    anova_tables = []
    for network in networks:
        cestcol = "avgCEST_" + network
        
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]

            ##################################
            # Define Linear Regression formula and model
            formula = f'{CNB_score} ~ {cestcol} + {network}'
            model = smf.ols(formula=formula, data=graph_df).fit()

            print('Intercept:', model.params[0])
            print('Coefficients:', model.params[1:])

            # Perform ANOVA and print results
            anova_table = sm.stats.anova_lm(model, typ=2)
            anova_tables.append(anova_table)
            print(network + "-" + CNB_score + " ANOVA Results:")
            print(anova_table)
            
            
            
            
            
            
            
            
            
            
            
            
              # Adjust diagnostic Labels
        value_counts = grp_df['dx_pscat'].value_counts()
        print(value_counts)
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
        grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NaN', 'Other')
        
        value_counts = grp_df['dx_pscat'].value_counts()
        print(value_counts)
        print(grp_df)
        # Make bar graph comparing diagnostic groups
        avg_df = graph_df.groupby('dx_pscat').agg({cestcol: ['mean', 'std'], network: ['mean', 'std']}).reset_index()
        # Flatten the multi-level columns
        avg_df.columns = ['_'.join(col).strip() for col in avg_df.columns.values]
        print(avg_df)
 
        colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'Blues_d', 'terrain_r']}) # 

    
for network in networks:
    cestcol = "avgCEST_" + network
  #  graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
    graph_df = graph_df.dropna(subset=[network, cestcol, 'dx_pscat'])
    # Create a linear regression model for fcon
    color = colors.loc[palette['Network'] == network, 'Color'].values[0]
    sns.set_palette(color)
    plot = sns.lmplot(x=network, y=cestcol,  data=graph_df) #hue='dx_pscat',
    if network == "SalVentAttn":
        print("yes")
        plt.xlabel("SN")
    else:
        plt.xlabel(network)
    plt.ylabel(cestcol)
    # Generate and add slope, r2 and p for subset 1
    slope, intercept, r_value, p_value, std_err = linregress(graph_df.loc[graph_df['dx_pscat'] == 'PSY', network], graph_df.loc[graph_df['dx_pscat'] == 'PSY', cestcol])
    plt.text(0.1, 0.8, f'PSY Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    # Generate and add slope, r2 and p for subset 2
    slope, intercept, r_value, p_value, std_err = linregress(graph_df[network], graph_df[cestcol])
    plt.text(0.4, 0.8, f'HC Group\nSlope: {slope:.2f}\nR^2: {r_value**2:.2f}\np: {p_value:.2f}', transform=plt.gca().transAxes)
    
    plt.title('Linear Regression between ' + network + ' fcon and ' + network + ' cest')
    plt.show() 
        


#BBS2

from sklearn import linear_model
import statsmodels.api as sm
import statsmodels.formula.api as smf
import numpy as np
import matplotlib.pyplot as plt

if run_grpanalysis:
    # Curate data 
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('NC', 'HC')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PROR', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('PRO', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('S', 'PSY')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('O', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('Unknown', 'Other')
    grp_df['dx_pscat'] = grp_df['dx_pscat'].replace('MDD', 'Other')
    value_counts = grp_df['dx_pscat'].value_counts()
    print(value_counts)
    
    colors = pd.DataFrame({'Network': ["Cont", "Default", "DorsAttn", "Vis", "SalVentAttn", "SomMot", "Limbic"],
        'Color': ['PuOr', 'PuRd_r', 'PiYG_r', 'PRGn', 'PiYG', 'GnBu_r', 'terrain_r']}) # 
    
    anova_tables = []
    # Create a scatter plot with a multiple linear regression 
    for network in networks:
        cestcol = "avgCEST_" + network
        # Create a linear regression model for fcon
       # color = colors.loc[colors['Network'] == network, 'Color'].values[0]
       # sns.set_palette(color)

        # Create CNB correlation plot for each network fcon and cest 
        for CNB_score in CNB_scores:
         #   graph_df = grp_df[grp_df['dx_pscat'] != 'Other']
            graph_df = grp_df
            graph_df = graph_df.dropna(subset=[CNB_score, cestcol, network])
            graph_df = graph_df[[CNB_score, cestcol, network]]
            # Define x values and target variable
            X = graph_df[[cestcol, network]]
            Y = graph_df[CNB_score]
            
            ##################################
            # Define formula and model
            #formula = f'{CNB_score} ~ {cestcol} + {network}'
            #model = smf.ols(formula=formula, data=graph_df).fit()
            #print(network + CNB_score)
            #print(model.summary())
            print(graph_df)
            fig = plt.figure()
            ax = fig.add_subplot(111, projection = '3d')
            ax.scatter(graph_df[CNB_score], graph_df[cestcol], graph_df[network])
            ax.set_xlabel(CNB_score)
            ax.set_ylabel(cestcol)
            ax.set_zlabel(network)
            plt.show()
            
            

